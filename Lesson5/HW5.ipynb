{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "dc4787fa-27e5-4aa6-aaf7-ac3f471be879",
      "metadata": {
        "id": "dc4787fa-27e5-4aa6-aaf7-ac3f471be879"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from nltk.tag import DefaultTagger\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger, TrigramTagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cd4d9722-4861-4f92-884b-0cb7b34b9031",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd4d9722-4861-4f92-884b-0cb7b34b9031",
        "outputId": "0a49ee7a-b4e3-47a9-8aba-17099de51054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyconll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44e6a6fa-897d-4076-9385-0482c7625e0d",
      "metadata": {
        "id": "44e6a6fa-897d-4076-9385-0482c7625e0d"
      },
      "outputs": [],
      "source": [
        "import pyconll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "798ffda3-b332-4b8b-8fe0-da939963b542",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798ffda3-b332-4b8b-8fe0-da939963b542",
        "outputId": "5267c9fa-2c44-4046-ad6a-2c604f8f9d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-17 18:04:00--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-c.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32367464 (31M) [text/plain]\n",
            "Saving to: ‘./ru_syntagrus-ud-train.conllu’\n",
            "\n",
            "./ru_syntagrus-ud-t 100%[===================>]  30.87M   126MB/s    in 0.2s    \n",
            "\n",
            "2022-07-17 18:04:01 (126 MB/s) - ‘./ru_syntagrus-ud-train.conllu’ saved [32367464/32367464]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O ./ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-c.conllu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a5b48201-ebcc-49fd-adad-3dd2c616914f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5b48201-ebcc-49fd-adad-3dd2c616914f",
        "outputId": "22175a90-4b34-4432-d365-f65432e7a4e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-17 18:04:01--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14704579 (14M) [text/plain]\n",
            "Saving to: ‘./ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "./ru_syntagrus-ud-d 100%[===================>]  14.02M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-07-17 18:04:01 (124 MB/s) - ‘./ru_syntagrus-ud-dev.conllu’ saved [14704579/14704579]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O ./ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e8b40b9c-0c95-41d8-821f-1de923192375",
      "metadata": {
        "id": "e8b40b9c-0c95-41d8-821f-1de923192375"
      },
      "outputs": [],
      "source": [
        "full_train = pyconll.load_from_file('./ru_syntagrus-ud-train.conllu')\n",
        "full_test = pyconll.load_from_file('./ru_syntagrus-ud-dev.conllu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a7fa77fb-bb70-460d-a247-d33d5225136c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7fa77fb-bb70-460d-a247-d33d5225136c",
        "outputId": "1531c41d-791c-49c8-bff6-0c812da2da91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20816"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(full_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bbad216e-cee7-4322-802f-4e892f714b95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbad216e-cee7-4322-802f-4e892f714b95",
        "outputId": "05e1f161-6c18-41f0-a090-bd8b1f97fd81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8906"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(full_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b8de9e8b-5771-4990-8f6e-4e319fdcc630",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8de9e8b-5771-4990-8f6e-4e319fdcc630",
        "outputId": "5096ea8c-3419-4f1e-aef8-3e12c4ead61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Моя DET\n",
            "мать NOUN\n",
            ", PUNCT\n",
            "Анна PROPN\n",
            "Всеволодовна PROPN\n",
            "Мохова PROPN\n",
            "( PUNCT\n",
            "Дмитриева PROPN\n",
            ") PUNCT\n",
            ", PUNCT\n",
            "родилась VERB\n",
            "27 ADJ\n",
            "марта NOUN\n",
            "1913 ADJ\n",
            "года NOUN\n",
            ". PUNCT\n",
            "<pyconll.unit.sentence.Sentence object at 0x7f98fd0ba050>\n",
            "Отец NOUN\n",
            "ее DET\n",
            ", PUNCT\n",
            "Всеволод PROPN\n",
            "Нестерович PROPN\n",
            "Дмитриев PROPN\n",
            ", PUNCT\n",
            "служил VERB\n",
            "тогда ADV\n",
            "егерем NOUN\n",
            "при ADP\n",
            "императорской ADJ\n",
            "охотничьей ADJ\n",
            "усадьбе NOUN\n",
            "в ADP\n",
            "Карелии PROPN\n",
            ". PUNCT\n",
            "<pyconll.unit.sentence.Sentence object at 0x7f98fd0ba0b0>\n"
          ]
        }
      ],
      "source": [
        "for sent in full_train[:2]:\n",
        "    for token in sent:\n",
        "        print(token.form, token.upos)\n",
        "    print(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cbde9a70-418d-48c9-ae30-ee73b6462537",
      "metadata": {
        "id": "cbde9a70-418d-48c9-ae30-ee73b6462537"
      },
      "outputs": [],
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "    \n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_sent_test.append([token.form for token in sent])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f82b9dce-93a8-4a2a-b65b-2c8f395ab4a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f82b9dce-93a8-4a2a-b65b-2c8f395ab4a5",
        "outputId": "01aa8f53-1c49-4813-a3ae-aa6b494898c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Наибольшая длина предложения 98\n",
            "Наибольшая длина токена 30\n"
          ]
        }
      ],
      "source": [
        "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
        "MAX_ORIG_TOKEN_LEN = max(len(\"\" if token.form is None else token.form) for sent in full_train for token in sent)\n",
        "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
        "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0c06636d-c788-4bb1-9715-6c20e40f2937",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c06636d-c788-4bb1-9715-6c20e40f2937",
        "outputId": "1317fd76-ae93-4752-e645-093af3cbd3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Моя мать , Анна Всеволодовна Мохова ( Дмитриева ) , родилась 27 марта 1913 года .\n",
            "Отец ее , Всеволод Нестерович Дмитриев , служил тогда егерем при императорской охотничьей усадьбе в Карелии .\n",
            "У Анны был старший брат , Борис , расстрелянный в середине 1930-х .\n",
            "Он заведовал мелким полустанком на Октябрьской ( Николаевской ) железной дороге , соединяющей Ленинград и Москву .\n",
            "Случилось крушение с жертвами , Бориса обвинили в диверсии и расстреляли .\n",
            "Младшая сестра Анны , Нина , умерла от туберкулеза тоже в середине 1930-х , успев родить сына Виктора .\n",
            "Семья простая , крестьянская , никаких документальных сведений о предках не хранила .\n",
            "По слухам , однако , почти все мы , бедные пасынки природы , с одного приладожского пятачка : Нева , Волхов , Карелия .\n",
            "Разве что отец явился с востока , из Вологды .\n",
            "Есть еще одно известное и важное исключение : мать моего отца - цыганка ( Надя , конечно ) , случайно забредшая в Вологду и сошедшаяся там с девятнадцатилетним Васей , отчего родился мой отец Павел .\n"
          ]
        }
      ],
      "source": [
        "all_train_texts = [' '.join(\"\" if token.form is None else token.form for token in sent) for sent in full_train]\n",
        "all_test_texts = [' '.join(\"\" if token.form is None else token.form for token in sent) for sent in full_test]\n",
        "\n",
        "all_train_labels = [' '.join(\"\" if token.form is None else token.form for token in sent) for sent in full_train]\n",
        "all_test_labels = [' '.join(\"\" if token.form is None else token.form for token in sent) for sent in full_test]\n",
        "print('\\n'.join(all_train_texts[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fc3725e4-925e-4ac9-a6b3-b2efa6a5908d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "fc3725e4-925e-4ac9-a6b3-b2efa6a5908d",
        "outputId": "ad00a970-def7-443e-9bae-dabbeadf76a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'DET'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'DET'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'PART'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'PART'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', 'NOUN'),\n",
              " ('XVI', 'ADJ'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8013933198775962"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "display(unigram_tagger.tag(fdata_sent_test[100]), unigram_tagger.evaluate(fdata_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "355654d6-55b4-4344-9909-1e83773af86f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "355654d6-55b4-4344-9909-1e83773af86f",
        "outputId": "c94f4686-8d9a-4408-d621-ddfb62813b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'DET'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'DET'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'PART'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'PART'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', 'NOUN'),\n",
              " ('XVI', 'ADJ'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8057946480890683"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "display(bigram_tagger.tag(fdata_sent_test[100]), bigram_tagger.evaluate(fdata_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "433e23c3-7784-40c6-acab-da3fc4c5992a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "433e23c3-7784-40c6-acab-da3fc4c5992a",
        "outputId": "34ff8b25-d769-4325-84de-5c4777730e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('Это', 'PRON'),\n",
              " ('сочинение', 'NOUN'),\n",
              " ('известно', 'ADJ'),\n",
              " ('во', 'ADP'),\n",
              " ('многих', 'PRON'),\n",
              " ('вариантах', 'NOUN'),\n",
              " ('(', 'PUNCT'),\n",
              " ('самые', 'DET'),\n",
              " ('ранние', 'ADJ'),\n",
              " ('из', 'ADP'),\n",
              " ('них', 'PRON'),\n",
              " ('почти', 'PART'),\n",
              " ('на', 'ADP'),\n",
              " ('сто', 'NUM'),\n",
              " ('лет', 'NOUN'),\n",
              " ('старше', 'ADJ'),\n",
              " (')', 'PUNCT'),\n",
              " ('и', 'CCONJ'),\n",
              " ('восходит', 'VERB'),\n",
              " ('к', 'ADP'),\n",
              " ('ещё', 'PART'),\n",
              " ('более', 'ADV'),\n",
              " ('древним', 'ADJ'),\n",
              " ('рукописям', 'NOUN'),\n",
              " ('XVI', 'ADJ'),\n",
              " ('в', 'ADP'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8043687740087245"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "display(trigram_tagger.tag(fdata_sent_test[100]), trigram_tagger.evaluate(fdata_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f8b76a0a-f607-4133-8a71-54c4af3c2a7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8b76a0a-f607-4133-8a71-54c4af3c2a7f",
        "outputId": "2b4053c7-227d-49a8-e119-5cc76458effa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8046292076307051"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN') \n",
        "tag = backoff_tagger(fdata_train,  \n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
        "                     backoff = backoff) \n",
        "  \n",
        "tag.evaluate(fdata_test) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03df1d12-da5c-4e50-964e-ee61a2d64401",
      "metadata": {
        "id": "03df1d12-da5c-4e50-964e-ee61a2d64401"
      },
      "source": [
        "Биграммный справляется лучше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "dca7c24c-064b-4244-8048-be57573f505b",
      "metadata": {
        "id": "dca7c24c-064b-4244-8048-be57573f505b"
      },
      "outputs": [],
      "source": [
        "train_tok = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for tok in sent:\n",
        "        train_tok.append('NO_TOK' if tok[0] is None else tok[0])\n",
        "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
        "        \n",
        "test_tok = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for tok in sent:\n",
        "        test_tok.append('NO_TOK' if tok[0] is None else tok[0])\n",
        "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7a360617-257f-4ae1-896b-e8dee2d8c19a",
      "metadata": {
        "id": "7a360617-257f-4ae1-896b-e8dee2d8c19a"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "#import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "faab1a2a-0071-4a50-99b1-8fbd10657f1b",
      "metadata": {
        "id": "faab1a2a-0071-4a50-99b1-8fbd10657f1b"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ff61322e-5b88-4dd9-bb78-dbafb2f79561",
      "metadata": {
        "id": "ff61322e-5b88-4dd9-bb78-dbafb2f79561"
      },
      "outputs": [],
      "source": [
        "test_enc_labels = le.transform(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b9e4f35c-fc0c-45e4-9e0c-251da26c6ce6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9e4f35c-fc0c-45e4-9e0c-251da26c6ce6",
        "outputId": "57ba6ac6-e327-44b8-90b8-db942c300e22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
              "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
              "       'VERB', 'X'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bcb48cbd-93e5-4dc1-8bef-f0fea205357c",
      "metadata": {
        "id": "bcb48cbd-93e5-4dc1-8bef-f0fea205357c"
      },
      "outputs": [],
      "source": [
        "def vectorization(vectorizer, train, test, train_enc_labels, test_enc_labels):\n",
        "    X_train = vectorizer.fit_transform(train)\n",
        "    X_test = vectorizer.transform(test)\n",
        "    \n",
        "    lr = LogisticRegression(random_state=0, max_iter=10)\n",
        "    lr.fit(X_train, train_enc_labels)\n",
        "    \n",
        "    pred = lr.predict(X_test)\n",
        "    \n",
        "    return accuracy_score(test_enc_labels, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b166f63e-4d82-43b8-89a2-e7d29325736a",
      "metadata": {
        "id": "b166f63e-4d82-43b8-89a2-e7d29325736a"
      },
      "outputs": [],
      "source": [
        "hvectorizer = HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=1000)\n",
        "cvectorizer = CountVectorizer(ngram_range=(1, 3), analyzer='char')\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "029de69d-7653-489b-9c6b-6b3d5a3e3953",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "029de69d-7653-489b-9c6b-6b3d5a3e3953",
        "outputId": "ffa0fd8d-6c4b-4731-b572-25f0194cbf38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6465785532912299"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "vectorization(hvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e762416d-6bd6-42cb-b7bd-c72479f25a1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e762416d-6bd6-42cb-b7bd-c72479f25a1e",
        "outputId": "dc56ca06-48a0-495c-d8b2-3caf35aa96c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7835275734097272"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "vectorization(cvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e9170351-2296-491d-8000-27fe9f936293",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9170351-2296-491d-8000-27fe9f936293",
        "outputId": "cec21515-4399-4161-f9a3-016c3326f144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7094797838400938"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vectorization(tfidfvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e271ffaf-e298-4089-9ed4-c073d531cb01",
      "metadata": {
        "id": "e271ffaf-e298-4089-9ed4-c073d531cb01"
      },
      "outputs": [],
      "source": [
        "hvectorizer = HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=1000)\n",
        "cvectorizer = CountVectorizer(ngram_range=(1, 3), analyzer='word')\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='word')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9baf406f-3c2b-4ec8-b6dc-979e8ba166b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9baf406f-3c2b-4ec8-b6dc-979e8ba166b2",
        "outputId": "235a6a08-e9ae-4ffe-dcbd-43918b698bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3318835861709747"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "vectorization(hvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1dce865c-b683-4a9e-8d9b-e0895223ae87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dce865c-b683-4a9e-8d9b-e0895223ae87",
        "outputId": "c5059e5f-7fbe-4581-bd49-576da5c8341f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3106322026173579"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "vectorization(cvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3002fcf6-b422-42db-a8c1-c5a850348011",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3002fcf6-b422-42db-a8c1-c5a850348011",
        "outputId": "b06006f3-064b-499a-f858-55c8b7998934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3126245198255095"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "vectorization(tfidfvectorizer, train_tok, test_tok, train_enc_labels, test_enc_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b5bd6442-4dec-4a88-a15e-31424b0fae43",
      "metadata": {
        "id": "b5bd6442-4dec-4a88-a15e-31424b0fae43"
      },
      "outputs": [],
      "source": [
        "#VERB\n",
        "tok_verb = []\n",
        "for sent in full_train[:]:\n",
        "    for token in sent:\n",
        "        if token.upos == 'VERB':\n",
        "            tok_verb.append(token.form)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d98aaf6a-b823-40af-8d8a-5806fb4425f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d98aaf6a-b823-40af-8d8a-5806fb4425f1",
        "outputId": "77903290-1e04-48ad-8ce4-939e034cafd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('сказала', 'VERB')]\n",
            "[('Слушала', 'VERB')]\n",
            "[('Калитка', None)]\n"
          ]
        }
      ],
      "source": [
        "from nltk.tag import SequentialBackoffTagger\n",
        "\n",
        "class VerbTagger(SequentialBackoffTagger):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        SequentialBackoffTagger.__init__(self, *args, **kwargs)\n",
        "        self.verb_set = set([n.lower() for n in tok_verb])\n",
        "            \n",
        "    def choose_tag(self, tokens, index, history):\n",
        "        word = tokens[index]\n",
        "        if word.lower() in self.verb_set:\n",
        "             return 'VERB'\n",
        "        else:\n",
        "             return None\n",
        "            \n",
        "nt = VerbTagger()\n",
        "print(nt.tag(['сказала'])) \n",
        "print(nt.tag(['Слушала'])) \n",
        "print(nt.tag(['Калитка']))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2c0406d1-bded-4edd-927b-e10b14cd4748",
      "metadata": {
        "id": "2c0406d1-bded-4edd-927b-e10b14cd4748"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "419b6276-fce5-4235-9bd0-16edc945abc4",
      "metadata": {
        "id": "419b6276-fce5-4235-9bd0-16edc945abc4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a021ed91-4102-430e-88e3-d01936912eea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a021ed91-4102-430e-88e3-d01936912eea",
        "outputId": "b1451f9d-22c7-4c63-ad34-b48fb814f583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: corus in /usr/local/lib/python3.7/dist-packages (0.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install corus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61e57b84-ade1-49dd-adac-9db29693ee68",
      "metadata": {
        "id": "61e57b84-ade1-49dd-adac-9db29693ee68"
      },
      "outputs": [],
      "source": [
        "import corus\n",
        "from corus import load_ne5\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "febcda84-94c6-4a6a-b334-dfdb3bb20ebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "febcda84-94c6-4a6a-b334-dfdb3bb20ebf",
        "outputId": "79b25613-4515-4fe6-cf57-a31c27aaa569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-17 18:06:20--  http://www.labinform.ru/pub/named_entities/collection5.zip\n",
            "Resolving www.labinform.ru (www.labinform.ru)... 95.181.230.181\n",
            "Connecting to www.labinform.ru (www.labinform.ru)|95.181.230.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1899530 (1.8M) [application/zip]\n",
            "Saving to: ‘collection5.zip’\n",
            "\n",
            "collection5.zip     100%[===================>]   1.81M  1.90MB/s    in 1.0s    \n",
            "\n",
            "2022-07-17 18:06:21 (1.90 MB/s) - ‘collection5.zip’ saved [1899530/1899530]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fd2ca121-4ce9-43e6-9471-61282a9d162c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd2ca121-4ce9-43e6-9471-61282a9d162c",
        "outputId": "79147d69-6f85-4724-ddf2-caa2fc0581a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  collection5.zip\n",
            "   creating: Collection5/\n",
            "  inflating: Collection5/001.ann     \n",
            "  inflating: Collection5/001.txt     \n",
            "  inflating: Collection5/002.ann     \n",
            "  inflating: Collection5/002.txt     \n",
            "  inflating: Collection5/003.ann     \n",
            "  inflating: Collection5/003.txt     \n",
            "  inflating: Collection5/004.ann     \n",
            "  inflating: Collection5/004.txt     \n",
            "  inflating: Collection5/005.ann     \n",
            "  inflating: Collection5/005.txt     \n",
            "  inflating: Collection5/006.ann     \n",
            "  inflating: Collection5/006.txt     \n",
            "  inflating: Collection5/007.ann     \n",
            "  inflating: Collection5/007.txt     \n",
            "  inflating: Collection5/008.ann     \n",
            "  inflating: Collection5/008.txt     \n",
            "  inflating: Collection5/009.ann     \n",
            "  inflating: Collection5/009.txt     \n",
            "  inflating: Collection5/010.ann     \n",
            "  inflating: Collection5/010.txt     \n",
            "  inflating: Collection5/011.ann     \n",
            "  inflating: Collection5/011.txt     \n",
            "  inflating: Collection5/012.ann     \n",
            "  inflating: Collection5/012.txt     \n",
            "  inflating: Collection5/013.ann     \n",
            "  inflating: Collection5/013.txt     \n",
            "  inflating: Collection5/014.ann     \n",
            "  inflating: Collection5/014.txt     \n",
            "  inflating: Collection5/015 (!).ann  \n",
            "  inflating: Collection5/015 (!).txt  \n",
            "  inflating: Collection5/016.ann     \n",
            "  inflating: Collection5/016.txt     \n",
            "  inflating: Collection5/017.ann     \n",
            "  inflating: Collection5/017.txt     \n",
            "  inflating: Collection5/018.ann     \n",
            "  inflating: Collection5/018.txt     \n",
            "  inflating: Collection5/019.ann     \n",
            "  inflating: Collection5/019.txt     \n",
            "  inflating: Collection5/020.ann     \n",
            "  inflating: Collection5/020.txt     \n",
            "  inflating: Collection5/021.ann     \n",
            "  inflating: Collection5/021.txt     \n",
            "  inflating: Collection5/022.ann     \n",
            "  inflating: Collection5/022.txt     \n",
            "  inflating: Collection5/023.ann     \n",
            "  inflating: Collection5/023.txt     \n",
            "  inflating: Collection5/025.ann     \n",
            "  inflating: Collection5/025.txt     \n",
            "  inflating: Collection5/026.ann     \n",
            "  inflating: Collection5/026.txt     \n",
            "  inflating: Collection5/027.ann     \n",
            "  inflating: Collection5/027.txt     \n",
            "  inflating: Collection5/028.ann     \n",
            "  inflating: Collection5/028.txt     \n",
            "  inflating: Collection5/029.ann     \n",
            "  inflating: Collection5/029.txt     \n",
            "  inflating: Collection5/030.ann     \n",
            "  inflating: Collection5/030.txt     \n",
            "  inflating: Collection5/031.ann     \n",
            "  inflating: Collection5/031.txt     \n",
            "  inflating: Collection5/032.ann     \n",
            "  inflating: Collection5/032.txt     \n",
            "  inflating: Collection5/033.ann     \n",
            "  inflating: Collection5/033.txt     \n",
            "  inflating: Collection5/034.ann     \n",
            "  inflating: Collection5/034.txt     \n",
            "  inflating: Collection5/035.ann     \n",
            "  inflating: Collection5/035.txt     \n",
            "  inflating: Collection5/036.ann     \n",
            "  inflating: Collection5/036.txt     \n",
            "  inflating: Collection5/037.ann     \n",
            "  inflating: Collection5/037.txt     \n",
            "  inflating: Collection5/038.ann     \n",
            "  inflating: Collection5/038.txt     \n",
            "  inflating: Collection5/039.ann     \n",
            "  inflating: Collection5/039.txt     \n",
            "  inflating: Collection5/03_12_12a.ann  \n",
            "  inflating: Collection5/03_12_12a.txt  \n",
            "  inflating: Collection5/03_12_12b.ann  \n",
            "  inflating: Collection5/03_12_12b.txt  \n",
            "  inflating: Collection5/03_12_12c.ann  \n",
            "  inflating: Collection5/03_12_12c.txt  \n",
            "  inflating: Collection5/03_12_12d.ann  \n",
            "  inflating: Collection5/03_12_12d.txt  \n",
            "  inflating: Collection5/03_12_12g.ann  \n",
            "  inflating: Collection5/03_12_12g.txt  \n",
            "  inflating: Collection5/03_12_12h.ann  \n",
            "  inflating: Collection5/03_12_12h.txt  \n",
            "  inflating: Collection5/040.ann     \n",
            "  inflating: Collection5/040.txt     \n",
            "  inflating: Collection5/041.ann     \n",
            "  inflating: Collection5/041.txt     \n",
            "  inflating: Collection5/042.ann     \n",
            "  inflating: Collection5/042.txt     \n",
            "  inflating: Collection5/043.ann     \n",
            "  inflating: Collection5/043.txt     \n",
            "  inflating: Collection5/044.ann     \n",
            "  inflating: Collection5/044.txt     \n",
            "  inflating: Collection5/045.ann     \n",
            "  inflating: Collection5/045.txt     \n",
            "  inflating: Collection5/046.ann     \n",
            "  inflating: Collection5/046.txt     \n",
            "  inflating: Collection5/047.ann     \n",
            "  inflating: Collection5/047.txt     \n",
            "  inflating: Collection5/048.ann     \n",
            "  inflating: Collection5/048.txt     \n",
            "  inflating: Collection5/049.ann     \n",
            "  inflating: Collection5/049.txt     \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.ann  \n",
            "  inflating: Collection5/04_02_13a_abdulatipov.txt  \n",
            "  inflating: Collection5/04_03_13a_sorokin.ann  \n",
            "  inflating: Collection5/04_03_13a_sorokin.txt  \n",
            "  inflating: Collection5/04_12_12b.ann  \n",
            "  inflating: Collection5/04_12_12b.txt  \n",
            "  inflating: Collection5/04_12_12d.ann  \n",
            "  inflating: Collection5/04_12_12d.txt  \n",
            "  inflating: Collection5/04_12_12f.ann  \n",
            "  inflating: Collection5/04_12_12f.txt  \n",
            "  inflating: Collection5/04_12_12g.ann  \n",
            "  inflating: Collection5/04_12_12g.txt  \n",
            "  inflating: Collection5/04_12_12h_corr.ann  \n",
            "  inflating: Collection5/04_12_12h_corr.txt  \n",
            "  inflating: Collection5/050.ann     \n",
            "  inflating: Collection5/050.txt     \n",
            "  inflating: Collection5/051.ann     \n",
            "  inflating: Collection5/051.txt     \n",
            "  inflating: Collection5/052.ann     \n",
            "  inflating: Collection5/052.txt     \n",
            "  inflating: Collection5/053.ann     \n",
            "  inflating: Collection5/053.txt     \n",
            "  inflating: Collection5/054.ann     \n",
            "  inflating: Collection5/054.txt     \n",
            "  inflating: Collection5/055.ann     \n",
            "  inflating: Collection5/055.txt     \n",
            "  inflating: Collection5/056.ann     \n",
            "  inflating: Collection5/056.txt     \n",
            "  inflating: Collection5/057.ann     \n",
            "  inflating: Collection5/057.txt     \n",
            "  inflating: Collection5/058.ann     \n",
            "  inflating: Collection5/058.txt     \n",
            "  inflating: Collection5/059.ann     \n",
            "  inflating: Collection5/059.txt     \n",
            "  inflating: Collection5/060.ann     \n",
            "  inflating: Collection5/060.txt     \n",
            "  inflating: Collection5/061.ann     \n",
            "  inflating: Collection5/061.txt     \n",
            "  inflating: Collection5/062.ann     \n",
            "  inflating: Collection5/062.txt     \n",
            "  inflating: Collection5/063.ann     \n",
            "  inflating: Collection5/063.txt     \n",
            "  inflating: Collection5/064.ann     \n",
            "  inflating: Collection5/064.txt     \n",
            "  inflating: Collection5/065.ann     \n",
            "  inflating: Collection5/065.txt     \n",
            "  inflating: Collection5/066.ann     \n",
            "  inflating: Collection5/066.txt     \n",
            "  inflating: Collection5/067.ann     \n",
            "  inflating: Collection5/067.txt     \n",
            "  inflating: Collection5/068.ann     \n",
            "  inflating: Collection5/068.txt     \n",
            "  inflating: Collection5/069.ann     \n",
            "  inflating: Collection5/069.txt     \n",
            "  inflating: Collection5/070.ann     \n",
            "  inflating: Collection5/070.txt     \n",
            "  inflating: Collection5/071.ann     \n",
            "  inflating: Collection5/071.txt     \n",
            "  inflating: Collection5/072.ann     \n",
            "  inflating: Collection5/072.txt     \n",
            "  inflating: Collection5/073.ann     \n",
            "  inflating: Collection5/073.txt     \n",
            "  inflating: Collection5/074.ann     \n",
            "  inflating: Collection5/074.txt     \n",
            "  inflating: Collection5/075.ann     \n",
            "  inflating: Collection5/075.txt     \n",
            "  inflating: Collection5/076.ann     \n",
            "  inflating: Collection5/076.txt     \n",
            "  inflating: Collection5/077.ann     \n",
            "  inflating: Collection5/077.txt     \n",
            "  inflating: Collection5/078.ann     \n",
            "  inflating: Collection5/078.txt     \n",
            "  inflating: Collection5/079.ann     \n",
            "  inflating: Collection5/079.txt     \n",
            "  inflating: Collection5/080.ann     \n",
            "  inflating: Collection5/080.txt     \n",
            "  inflating: Collection5/081.ann     \n",
            "  inflating: Collection5/081.txt     \n",
            "  inflating: Collection5/082.ann     \n",
            "  inflating: Collection5/082.txt     \n",
            "  inflating: Collection5/083.ann     \n",
            "  inflating: Collection5/083.txt     \n",
            "  inflating: Collection5/084.ann     \n",
            "  inflating: Collection5/084.txt     \n",
            "  inflating: Collection5/085.ann     \n",
            "  inflating: Collection5/085.txt     \n",
            "  inflating: Collection5/086.ann     \n",
            "  inflating: Collection5/086.txt     \n",
            "  inflating: Collection5/087.ann     \n",
            "  inflating: Collection5/087.txt     \n",
            "  inflating: Collection5/088.ann     \n",
            "  inflating: Collection5/088.txt     \n",
            "  inflating: Collection5/089.ann     \n",
            "  inflating: Collection5/089.txt     \n",
            "  inflating: Collection5/090.ann     \n",
            "  inflating: Collection5/090.txt     \n",
            "  inflating: Collection5/091.ann     \n",
            "  inflating: Collection5/091.txt     \n",
            "  inflating: Collection5/092.ann     \n",
            "  inflating: Collection5/092.txt     \n",
            "  inflating: Collection5/093.ann     \n",
            "  inflating: Collection5/093.txt     \n",
            "  inflating: Collection5/094.ann     \n",
            "  inflating: Collection5/094.txt     \n",
            "  inflating: Collection5/095.ann     \n",
            "  inflating: Collection5/095.txt     \n",
            "  inflating: Collection5/096.ann     \n",
            "  inflating: Collection5/096.txt     \n",
            "  inflating: Collection5/097.ann     \n",
            "  inflating: Collection5/097.txt     \n",
            "  inflating: Collection5/098.ann     \n",
            "  inflating: Collection5/098.txt     \n",
            "  inflating: Collection5/099.ann     \n",
            "  inflating: Collection5/099.txt     \n",
            "  inflating: Collection5/09_01_13.ann  \n",
            "  inflating: Collection5/09_01_13.txt  \n",
            "  inflating: Collection5/09_01_13a.ann  \n",
            "  inflating: Collection5/09_01_13a.txt  \n",
            "  inflating: Collection5/09_01_13c.ann  \n",
            "  inflating: Collection5/09_01_13c.txt  \n",
            "  inflating: Collection5/09_01_13d.ann  \n",
            "  inflating: Collection5/09_01_13d.txt  \n",
            "  inflating: Collection5/09_01_13e.ann  \n",
            "  inflating: Collection5/09_01_13e.txt  \n",
            "  inflating: Collection5/09_01_13h.ann  \n",
            "  inflating: Collection5/09_01_13h.txt  \n",
            "  inflating: Collection5/09_01_13i.ann  \n",
            "  inflating: Collection5/09_01_13i.txt  \n",
            "  inflating: Collection5/100.ann     \n",
            "  inflating: Collection5/100.txt     \n",
            "  inflating: Collection5/1000.ann    \n",
            "  inflating: Collection5/1000.txt    \n",
            "  inflating: Collection5/1001.ann    \n",
            "  inflating: Collection5/1001.txt    \n",
            "  inflating: Collection5/1002.ann    \n",
            "  inflating: Collection5/1002.txt    \n",
            "  inflating: Collection5/1003.ann    \n",
            "  inflating: Collection5/1003.txt    \n",
            "  inflating: Collection5/1004.ann    \n",
            "  inflating: Collection5/1004.txt    \n",
            "  inflating: Collection5/1005.ann    \n",
            "  inflating: Collection5/1005.txt    \n",
            "  inflating: Collection5/1006.ann    \n",
            "  inflating: Collection5/1006.txt    \n",
            "  inflating: Collection5/1007.ann    \n",
            "  inflating: Collection5/1007.txt    \n",
            "  inflating: Collection5/1008.ann    \n",
            "  inflating: Collection5/1008.txt    \n",
            "  inflating: Collection5/1009.ann    \n",
            "  inflating: Collection5/1009.txt    \n",
            "  inflating: Collection5/101.ann     \n",
            "  inflating: Collection5/101.txt     \n",
            "  inflating: Collection5/1010.ann    \n",
            "  inflating: Collection5/1010.txt    \n",
            "  inflating: Collection5/1011.ann    \n",
            "  inflating: Collection5/1011.txt    \n",
            "  inflating: Collection5/1012.ann    \n",
            "  inflating: Collection5/1012.txt    \n",
            "  inflating: Collection5/1013.ann    \n",
            "  inflating: Collection5/1013.txt    \n",
            "  inflating: Collection5/1014.ann    \n",
            "  inflating: Collection5/1014.txt    \n",
            "  inflating: Collection5/1015.ann    \n",
            "  inflating: Collection5/1015.txt    \n",
            "  inflating: Collection5/1016.ann    \n",
            "  inflating: Collection5/1016.txt    \n",
            "  inflating: Collection5/1017.ann    \n",
            "  inflating: Collection5/1017.txt    \n",
            "  inflating: Collection5/1018.ann    \n",
            "  inflating: Collection5/1018.txt    \n",
            "  inflating: Collection5/1019.ann    \n",
            "  inflating: Collection5/1019.txt    \n",
            "  inflating: Collection5/102.ann     \n",
            "  inflating: Collection5/102.txt     \n",
            "  inflating: Collection5/1020.ann    \n",
            "  inflating: Collection5/1020.txt    \n",
            "  inflating: Collection5/1021.ann    \n",
            "  inflating: Collection5/1021.txt    \n",
            "  inflating: Collection5/1022.ann    \n",
            "  inflating: Collection5/1022.txt    \n",
            "  inflating: Collection5/1023.ann    \n",
            "  inflating: Collection5/1023.txt    \n",
            "  inflating: Collection5/1024.ann    \n",
            "  inflating: Collection5/1024.txt    \n",
            "  inflating: Collection5/1025.ann    \n",
            "  inflating: Collection5/1025.txt    \n",
            "  inflating: Collection5/1026.ann    \n",
            "  inflating: Collection5/1026.txt    \n",
            "  inflating: Collection5/1027.ann    \n",
            "  inflating: Collection5/1027.txt    \n",
            "  inflating: Collection5/1028.ann    \n",
            "  inflating: Collection5/1028.txt    \n",
            "  inflating: Collection5/1029.ann    \n",
            "  inflating: Collection5/1029.txt    \n",
            "  inflating: Collection5/103.ann     \n",
            "  inflating: Collection5/103.txt     \n",
            "  inflating: Collection5/1030.ann    \n",
            "  inflating: Collection5/1030.txt    \n",
            "  inflating: Collection5/1031.ann    \n",
            "  inflating: Collection5/1031.txt    \n",
            "  inflating: Collection5/1032.ann    \n",
            "  inflating: Collection5/1032.txt    \n",
            "  inflating: Collection5/1033.ann    \n",
            "  inflating: Collection5/1033.txt    \n",
            "  inflating: Collection5/1034.ann    \n",
            "  inflating: Collection5/1034.txt    \n",
            "  inflating: Collection5/1035.ann    \n",
            "  inflating: Collection5/1035.txt    \n",
            "  inflating: Collection5/1036.ann    \n",
            "  inflating: Collection5/1036.txt    \n",
            "  inflating: Collection5/1037.ann    \n",
            "  inflating: Collection5/1037.txt    \n",
            "  inflating: Collection5/1038.ann    \n",
            "  inflating: Collection5/1038.txt    \n",
            "  inflating: Collection5/1039.ann    \n",
            "  inflating: Collection5/1039.txt    \n",
            "  inflating: Collection5/104.ann     \n",
            "  inflating: Collection5/104.txt     \n",
            "  inflating: Collection5/1040.ann    \n",
            "  inflating: Collection5/1040.txt    \n",
            "  inflating: Collection5/1041.ann    \n",
            "  inflating: Collection5/1041.txt    \n",
            "  inflating: Collection5/1042.ann    \n",
            "  inflating: Collection5/1042.txt    \n",
            "  inflating: Collection5/1043.ann    \n",
            "  inflating: Collection5/1043.txt    \n",
            "  inflating: Collection5/1044.ann    \n",
            "  inflating: Collection5/1044.txt    \n",
            "  inflating: Collection5/1045.ann    \n",
            "  inflating: Collection5/1045.txt    \n",
            "  inflating: Collection5/1046.ann    \n",
            "  inflating: Collection5/1046.txt    \n",
            "  inflating: Collection5/1047.ann    \n",
            "  inflating: Collection5/1047.txt    \n",
            "  inflating: Collection5/1048.ann    \n",
            "  inflating: Collection5/1048.txt    \n",
            "  inflating: Collection5/1049.ann    \n",
            "  inflating: Collection5/1049.txt    \n",
            "  inflating: Collection5/105.ann     \n",
            "  inflating: Collection5/105.txt     \n",
            "  inflating: Collection5/1050.ann    \n",
            "  inflating: Collection5/1050.txt    \n",
            "  inflating: Collection5/106.ann     \n",
            "  inflating: Collection5/106.txt     \n",
            "  inflating: Collection5/107.ann     \n",
            "  inflating: Collection5/107.txt     \n",
            "  inflating: Collection5/108.ann     \n",
            "  inflating: Collection5/108.txt     \n",
            "  inflating: Collection5/109.ann     \n",
            "  inflating: Collection5/109.txt     \n",
            "  inflating: Collection5/10_01_13a.ann  \n",
            "  inflating: Collection5/10_01_13a.txt  \n",
            "  inflating: Collection5/10_01_13d.ann  \n",
            "  inflating: Collection5/10_01_13d.txt  \n",
            "  inflating: Collection5/10_01_13i.ann  \n",
            "  inflating: Collection5/10_01_13i.txt  \n",
            "  inflating: Collection5/110.ann     \n",
            "  inflating: Collection5/110.txt     \n",
            "  inflating: Collection5/1100.ann    \n",
            "  inflating: Collection5/1100.txt    \n",
            "  inflating: Collection5/1101.ann    \n",
            "  inflating: Collection5/1101.txt    \n",
            "  inflating: Collection5/1102.ann    \n",
            "  inflating: Collection5/1102.txt    \n",
            "  inflating: Collection5/1103.ann    \n",
            "  inflating: Collection5/1103.txt    \n",
            "  inflating: Collection5/1104.ann    \n",
            "  inflating: Collection5/1104.txt    \n",
            "  inflating: Collection5/1105.ann    \n",
            "  inflating: Collection5/1105.txt    \n",
            "  inflating: Collection5/1106.ann    \n",
            "  inflating: Collection5/1106.txt    \n",
            "  inflating: Collection5/1107.ann    \n",
            "  inflating: Collection5/1107.txt    \n",
            "  inflating: Collection5/1108.ann    \n",
            "  inflating: Collection5/1108.txt    \n",
            "  inflating: Collection5/1109.ann    \n",
            "  inflating: Collection5/1109.txt    \n",
            "  inflating: Collection5/111.ann     \n",
            "  inflating: Collection5/111.txt     \n",
            "  inflating: Collection5/1110.ann    \n",
            "  inflating: Collection5/1110.txt    \n",
            "  inflating: Collection5/1111.ann    \n",
            "  inflating: Collection5/1111.txt    \n",
            "  inflating: Collection5/1112.ann    \n",
            "  inflating: Collection5/1112.txt    \n",
            "  inflating: Collection5/1113.ann    \n",
            "  inflating: Collection5/1113.txt    \n",
            "  inflating: Collection5/1114.ann    \n",
            "  inflating: Collection5/1114.txt    \n",
            "  inflating: Collection5/1115.ann    \n",
            "  inflating: Collection5/1115.txt    \n",
            "  inflating: Collection5/1116.ann    \n",
            "  inflating: Collection5/1116.txt    \n",
            "  inflating: Collection5/1117.ann    \n",
            "  inflating: Collection5/1117.txt    \n",
            "  inflating: Collection5/1118.ann    \n",
            "  inflating: Collection5/1118.txt    \n",
            "  inflating: Collection5/1119.ann    \n",
            "  inflating: Collection5/1119.txt    \n",
            "  inflating: Collection5/112.ann     \n",
            "  inflating: Collection5/112.txt     \n",
            "  inflating: Collection5/1120.ann    \n",
            "  inflating: Collection5/1120.txt    \n",
            "  inflating: Collection5/1121.ann    \n",
            "  inflating: Collection5/1121.txt    \n",
            "  inflating: Collection5/1122.ann    \n",
            "  inflating: Collection5/1122.txt    \n",
            "  inflating: Collection5/1123.ann    \n",
            "  inflating: Collection5/1123.txt    \n",
            "  inflating: Collection5/1124.ann    \n",
            "  inflating: Collection5/1124.txt    \n",
            "  inflating: Collection5/1125.ann    \n",
            "  inflating: Collection5/1125.txt    \n",
            "  inflating: Collection5/1126.ann    \n",
            "  inflating: Collection5/1126.txt    \n",
            "  inflating: Collection5/1127.ann    \n",
            "  inflating: Collection5/1127.txt    \n",
            "  inflating: Collection5/1128.ann    \n",
            "  inflating: Collection5/1128.txt    \n",
            "  inflating: Collection5/113.ann     \n",
            "  inflating: Collection5/113.txt     \n",
            "  inflating: Collection5/1130.ann    \n",
            "  inflating: Collection5/1130.txt    \n",
            "  inflating: Collection5/1131.ann    \n",
            "  inflating: Collection5/1131.txt    \n",
            "  inflating: Collection5/1132.ann    \n",
            "  inflating: Collection5/1132.txt    \n",
            "  inflating: Collection5/1133.ann    \n",
            "  inflating: Collection5/1133.txt    \n",
            "  inflating: Collection5/1134.ann    \n",
            "  inflating: Collection5/1134.txt    \n",
            "  inflating: Collection5/1135.ann    \n",
            "  inflating: Collection5/1135.txt    \n",
            "  inflating: Collection5/1136.ann    \n",
            "  inflating: Collection5/1136.txt    \n",
            "  inflating: Collection5/1137.ann    \n",
            "  inflating: Collection5/1137.txt    \n",
            "  inflating: Collection5/1138.ann    \n",
            "  inflating: Collection5/1138.txt    \n",
            "  inflating: Collection5/1139.ann    \n",
            "  inflating: Collection5/1139.txt    \n",
            "  inflating: Collection5/114.ann     \n",
            "  inflating: Collection5/114.txt     \n",
            "  inflating: Collection5/1140.ann    \n",
            "  inflating: Collection5/1140.txt    \n",
            "  inflating: Collection5/1141.ann    \n",
            "  inflating: Collection5/1141.txt    \n",
            "  inflating: Collection5/1142.ann    \n",
            "  inflating: Collection5/1142.txt    \n",
            "  inflating: Collection5/1143.ann    \n",
            "  inflating: Collection5/1143.txt    \n",
            "  inflating: Collection5/1144.ann    \n",
            "  inflating: Collection5/1144.txt    \n",
            "  inflating: Collection5/1145.ann    \n",
            "  inflating: Collection5/1145.txt    \n",
            "  inflating: Collection5/1146.ann    \n",
            "  inflating: Collection5/1146.txt    \n",
            "  inflating: Collection5/1147.ann    \n",
            "  inflating: Collection5/1147.txt    \n",
            "  inflating: Collection5/1148.ann    \n",
            "  inflating: Collection5/1148.txt    \n",
            "  inflating: Collection5/1149.ann    \n",
            "  inflating: Collection5/1149.txt    \n",
            "  inflating: Collection5/115.ann     \n",
            "  inflating: Collection5/115.txt     \n",
            "  inflating: Collection5/1150.ann    \n",
            "  inflating: Collection5/1150.txt    \n",
            "  inflating: Collection5/1151.ann    \n",
            "  inflating: Collection5/1151.txt    \n",
            "  inflating: Collection5/1152.ann    \n",
            "  inflating: Collection5/1152.txt    \n",
            "  inflating: Collection5/1153.ann    \n",
            "  inflating: Collection5/1153.txt    \n",
            "  inflating: Collection5/1154.ann    \n",
            "  inflating: Collection5/1154.txt    \n",
            "  inflating: Collection5/1155.ann    \n",
            "  inflating: Collection5/1155.txt    \n",
            "  inflating: Collection5/1156.ann    \n",
            "  inflating: Collection5/1156.txt    \n",
            "  inflating: Collection5/1157.ann    \n",
            "  inflating: Collection5/1157.txt    \n",
            "  inflating: Collection5/1158.ann    \n",
            "  inflating: Collection5/1158.txt    \n",
            "  inflating: Collection5/1159.ann    \n",
            "  inflating: Collection5/1159.txt    \n",
            "  inflating: Collection5/116.ann     \n",
            "  inflating: Collection5/116.txt     \n",
            "  inflating: Collection5/1160.ann    \n",
            "  inflating: Collection5/1160.txt    \n",
            "  inflating: Collection5/1161.ann    \n",
            "  inflating: Collection5/1161.txt    \n",
            "  inflating: Collection5/1162.ann    \n",
            "  inflating: Collection5/1162.txt    \n",
            "  inflating: Collection5/1163.ann    \n",
            "  inflating: Collection5/1163.txt    \n",
            "  inflating: Collection5/1164.ann    \n",
            "  inflating: Collection5/1164.txt    \n",
            "  inflating: Collection5/1165.ann    \n",
            "  inflating: Collection5/1165.txt    \n",
            "  inflating: Collection5/1166.ann    \n",
            "  inflating: Collection5/1166.txt    \n",
            "  inflating: Collection5/1167.ann    \n",
            "  inflating: Collection5/1167.txt    \n",
            "  inflating: Collection5/1168.ann    \n",
            "  inflating: Collection5/1168.txt    \n",
            "  inflating: Collection5/1169.ann    \n",
            "  inflating: Collection5/1169.txt    \n",
            "  inflating: Collection5/117.ann     \n",
            "  inflating: Collection5/117.txt     \n",
            "  inflating: Collection5/1170.ann    \n",
            "  inflating: Collection5/1170.txt    \n",
            "  inflating: Collection5/1171.ann    \n",
            "  inflating: Collection5/1171.txt    \n",
            "  inflating: Collection5/1172.ann    \n",
            "  inflating: Collection5/1172.txt    \n",
            "  inflating: Collection5/1173.ann    \n",
            "  inflating: Collection5/1173.txt    \n",
            "  inflating: Collection5/1174.ann    \n",
            "  inflating: Collection5/1174.txt    \n",
            "  inflating: Collection5/1175.ann    \n",
            "  inflating: Collection5/1175.txt    \n",
            "  inflating: Collection5/1176.ann    \n",
            "  inflating: Collection5/1176.txt    \n",
            "  inflating: Collection5/1177.ann    \n",
            "  inflating: Collection5/1177.txt    \n",
            "  inflating: Collection5/1178.ann    \n",
            "  inflating: Collection5/1178.txt    \n",
            "  inflating: Collection5/1179.ann    \n",
            "  inflating: Collection5/1179.txt    \n",
            "  inflating: Collection5/118.ann     \n",
            "  inflating: Collection5/118.txt     \n",
            "  inflating: Collection5/1180.ann    \n",
            "  inflating: Collection5/1180.txt    \n",
            "  inflating: Collection5/1181.ann    \n",
            "  inflating: Collection5/1181.txt    \n",
            "  inflating: Collection5/1182.ann    \n",
            "  inflating: Collection5/1182.txt    \n",
            "  inflating: Collection5/1183.ann    \n",
            "  inflating: Collection5/1183.txt    \n",
            "  inflating: Collection5/1184.ann    \n",
            "  inflating: Collection5/1184.txt    \n",
            "  inflating: Collection5/1185.ann    \n",
            "  inflating: Collection5/1185.txt    \n",
            "  inflating: Collection5/1186.ann    \n",
            "  inflating: Collection5/1186.txt    \n",
            "  inflating: Collection5/1187.ann    \n",
            "  inflating: Collection5/1187.txt    \n",
            "  inflating: Collection5/1188.ann    \n",
            "  inflating: Collection5/1188.txt    \n",
            "  inflating: Collection5/1189.ann    \n",
            "  inflating: Collection5/1189.txt    \n",
            "  inflating: Collection5/119.ann     \n",
            "  inflating: Collection5/119.txt     \n",
            "  inflating: Collection5/1190.ann    \n",
            "  inflating: Collection5/1190.txt    \n",
            "  inflating: Collection5/1191.ann    \n",
            "  inflating: Collection5/1191.txt    \n",
            "  inflating: Collection5/1192.ann    \n",
            "  inflating: Collection5/1192.txt    \n",
            "  inflating: Collection5/1193.ann    \n",
            "  inflating: Collection5/1193.txt    \n",
            "  inflating: Collection5/1194.ann    \n",
            "  inflating: Collection5/1194.txt    \n",
            "  inflating: Collection5/1195.ann    \n",
            "  inflating: Collection5/1195.txt    \n",
            "  inflating: Collection5/1196.ann    \n",
            "  inflating: Collection5/1196.txt    \n",
            "  inflating: Collection5/1197.ann    \n",
            "  inflating: Collection5/1197.txt    \n",
            "  inflating: Collection5/1198.ann    \n",
            "  inflating: Collection5/1198.txt    \n",
            "  inflating: Collection5/1199.ann    \n",
            "  inflating: Collection5/1199.txt    \n",
            "  inflating: Collection5/11_01_13b.ann  \n",
            "  inflating: Collection5/11_01_13b.txt  \n",
            "  inflating: Collection5/11_01_13e.ann  \n",
            "  inflating: Collection5/11_01_13e.txt  \n",
            "  inflating: Collection5/120.ann     \n",
            "  inflating: Collection5/120.txt     \n",
            "  inflating: Collection5/1200.ann    \n",
            "  inflating: Collection5/1200.txt    \n",
            "  inflating: Collection5/121.ann     \n",
            "  inflating: Collection5/121.txt     \n",
            "  inflating: Collection5/122.ann     \n",
            "  inflating: Collection5/122.txt     \n",
            "  inflating: Collection5/123.ann     \n",
            "  inflating: Collection5/123.txt     \n",
            "  inflating: Collection5/124.ann     \n",
            "  inflating: Collection5/124.txt     \n",
            "  inflating: Collection5/125.ann     \n",
            "  inflating: Collection5/125.txt     \n",
            "  inflating: Collection5/126.ann     \n",
            "  inflating: Collection5/126.txt     \n",
            "  inflating: Collection5/127.ann     \n",
            "  inflating: Collection5/127.txt     \n",
            "  inflating: Collection5/128.ann     \n",
            "  inflating: Collection5/128.txt     \n",
            "  inflating: Collection5/129.ann     \n",
            "  inflating: Collection5/129.txt     \n",
            "  inflating: Collection5/130.ann     \n",
            "  inflating: Collection5/130.txt     \n",
            "  inflating: Collection5/131.ann     \n",
            "  inflating: Collection5/131.txt     \n",
            "  inflating: Collection5/132.ann     \n",
            "  inflating: Collection5/132.txt     \n",
            "  inflating: Collection5/133.ann     \n",
            "  inflating: Collection5/133.txt     \n",
            "  inflating: Collection5/134.ann     \n",
            "  inflating: Collection5/134.txt     \n",
            "  inflating: Collection5/135.ann     \n",
            "  inflating: Collection5/135.txt     \n",
            "  inflating: Collection5/136.ann     \n",
            "  inflating: Collection5/136.txt     \n",
            "  inflating: Collection5/137.ann     \n",
            "  inflating: Collection5/137.txt     \n",
            "  inflating: Collection5/138.ann     \n",
            "  inflating: Collection5/138.txt     \n",
            "  inflating: Collection5/139.ann     \n",
            "  inflating: Collection5/139.txt     \n",
            "  inflating: Collection5/140.ann     \n",
            "  inflating: Collection5/140.txt     \n",
            "  inflating: Collection5/141.ann     \n",
            "  inflating: Collection5/141.txt     \n",
            "  inflating: Collection5/142.ann     \n",
            "  inflating: Collection5/142.txt     \n",
            "  inflating: Collection5/143.ann     \n",
            "  inflating: Collection5/143.txt     \n",
            "  inflating: Collection5/144.ann     \n",
            "  inflating: Collection5/144.txt     \n",
            "  inflating: Collection5/145.ann     \n",
            "  inflating: Collection5/145.txt     \n",
            "  inflating: Collection5/146.ann     \n",
            "  inflating: Collection5/146.txt     \n",
            "  inflating: Collection5/147.ann     \n",
            "  inflating: Collection5/147.txt     \n",
            "  inflating: Collection5/148.ann     \n",
            "  inflating: Collection5/148.txt     \n",
            "  inflating: Collection5/149.ann     \n",
            "  inflating: Collection5/149.txt     \n",
            "  inflating: Collection5/14_01_13c.ann  \n",
            "  inflating: Collection5/14_01_13c.txt  \n",
            "  inflating: Collection5/14_01_13g.ann  \n",
            "  inflating: Collection5/14_01_13g.txt  \n",
            "  inflating: Collection5/14_01_13i.ann  \n",
            "  inflating: Collection5/14_01_13i.txt  \n",
            "  inflating: Collection5/150.ann     \n",
            "  inflating: Collection5/150.txt     \n",
            "  inflating: Collection5/151.ann     \n",
            "  inflating: Collection5/151.txt     \n",
            "  inflating: Collection5/152.ann     \n",
            "  inflating: Collection5/152.txt     \n",
            "  inflating: Collection5/153.ann     \n",
            "  inflating: Collection5/153.txt     \n",
            "  inflating: Collection5/154.ann     \n",
            "  inflating: Collection5/154.txt     \n",
            "  inflating: Collection5/155.ann     \n",
            "  inflating: Collection5/155.txt     \n",
            "  inflating: Collection5/156.ann     \n",
            "  inflating: Collection5/156.txt     \n",
            "  inflating: Collection5/157.ann     \n",
            "  inflating: Collection5/157.txt     \n",
            "  inflating: Collection5/158.ann     \n",
            "  inflating: Collection5/158.txt     \n",
            "  inflating: Collection5/159.ann     \n",
            "  inflating: Collection5/159.txt     \n",
            "  inflating: Collection5/15_01_13a.ann  \n",
            "  inflating: Collection5/15_01_13a.txt  \n",
            "  inflating: Collection5/15_01_13b.ann  \n",
            "  inflating: Collection5/15_01_13b.txt  \n",
            "  inflating: Collection5/15_01_13e.ann  \n",
            "  inflating: Collection5/15_01_13e.txt  \n",
            "  inflating: Collection5/15_01_13f.ann  \n",
            "  inflating: Collection5/15_01_13f.txt  \n",
            "  inflating: Collection5/160.ann     \n",
            "  inflating: Collection5/160.txt     \n",
            "  inflating: Collection5/161.ann     \n",
            "  inflating: Collection5/161.txt     \n",
            "  inflating: Collection5/162.ann     \n",
            "  inflating: Collection5/162.txt     \n",
            "  inflating: Collection5/163.ann     \n",
            "  inflating: Collection5/163.txt     \n",
            "  inflating: Collection5/164.ann     \n",
            "  inflating: Collection5/164.txt     \n",
            "  inflating: Collection5/165.ann     \n",
            "  inflating: Collection5/165.txt     \n",
            "  inflating: Collection5/166.ann     \n",
            "  inflating: Collection5/166.txt     \n",
            "  inflating: Collection5/167.ann     \n",
            "  inflating: Collection5/167.txt     \n",
            "  inflating: Collection5/168.ann     \n",
            "  inflating: Collection5/168.txt     \n",
            "  inflating: Collection5/169.ann     \n",
            "  inflating: Collection5/169.txt     \n",
            "  inflating: Collection5/170.ann     \n",
            "  inflating: Collection5/170.txt     \n",
            "  inflating: Collection5/171.ann     \n",
            "  inflating: Collection5/171.txt     \n",
            "  inflating: Collection5/172.ann     \n",
            "  inflating: Collection5/172.txt     \n",
            "  inflating: Collection5/173.ann     \n",
            "  inflating: Collection5/173.txt     \n",
            "  inflating: Collection5/174.ann     \n",
            "  inflating: Collection5/174.txt     \n",
            "  inflating: Collection5/175.ann     \n",
            "  inflating: Collection5/175.txt     \n",
            "  inflating: Collection5/176.ann     \n",
            "  inflating: Collection5/176.txt     \n",
            "  inflating: Collection5/177.ann     \n",
            "  inflating: Collection5/177.txt     \n",
            "  inflating: Collection5/178.ann     \n",
            "  inflating: Collection5/178.txt     \n",
            "  inflating: Collection5/179.ann     \n",
            "  inflating: Collection5/179.txt     \n",
            "  inflating: Collection5/180.ann     \n",
            "  inflating: Collection5/180.txt     \n",
            "  inflating: Collection5/181.ann     \n",
            "  inflating: Collection5/181.txt     \n",
            "  inflating: Collection5/182.ann     \n",
            "  inflating: Collection5/182.txt     \n",
            "  inflating: Collection5/183.ann     \n",
            "  inflating: Collection5/183.txt     \n",
            "  inflating: Collection5/184.ann     \n",
            "  inflating: Collection5/184.txt     \n",
            "  inflating: Collection5/185.ann     \n",
            "  inflating: Collection5/185.txt     \n",
            "  inflating: Collection5/186.ann     \n",
            "  inflating: Collection5/186.txt     \n",
            "  inflating: Collection5/187.ann     \n",
            "  inflating: Collection5/187.txt     \n",
            "  inflating: Collection5/188.ann     \n",
            "  inflating: Collection5/188.txt     \n",
            "  inflating: Collection5/189.ann     \n",
            "  inflating: Collection5/189.txt     \n",
            "  inflating: Collection5/190.ann     \n",
            "  inflating: Collection5/190.txt     \n",
            "  inflating: Collection5/191.ann     \n",
            "  inflating: Collection5/191.txt     \n",
            "  inflating: Collection5/192.ann     \n",
            "  inflating: Collection5/192.txt     \n",
            "  inflating: Collection5/193.ann     \n",
            "  inflating: Collection5/193.txt     \n",
            "  inflating: Collection5/194.ann     \n",
            "  inflating: Collection5/194.txt     \n",
            "  inflating: Collection5/195.ann     \n",
            "  inflating: Collection5/195.txt     \n",
            "  inflating: Collection5/196.ann     \n",
            "  inflating: Collection5/196.txt     \n",
            "  inflating: Collection5/197.ann     \n",
            "  inflating: Collection5/197.txt     \n",
            "  inflating: Collection5/198.ann     \n",
            "  inflating: Collection5/198.txt     \n",
            "  inflating: Collection5/199.ann     \n",
            "  inflating: Collection5/199.txt     \n",
            "  inflating: Collection5/19_11_12d.ann  \n",
            "  inflating: Collection5/19_11_12d.txt  \n",
            "  inflating: Collection5/19_11_12h.ann  \n",
            "  inflating: Collection5/19_11_12h.txt  \n",
            "  inflating: Collection5/200.ann     \n",
            "  inflating: Collection5/200.txt     \n",
            "  inflating: Collection5/2001.ann    \n",
            "  inflating: Collection5/2001.txt    \n",
            "  inflating: Collection5/2002.ann    \n",
            "  inflating: Collection5/2002.txt    \n",
            "  inflating: Collection5/2003.ann    \n",
            "  inflating: Collection5/2003.txt    \n",
            "  inflating: Collection5/2004.ann    \n",
            "  inflating: Collection5/2004.txt    \n",
            "  inflating: Collection5/2005.ann    \n",
            "  inflating: Collection5/2005.txt    \n",
            "  inflating: Collection5/2006.ann    \n",
            "  inflating: Collection5/2006.txt    \n",
            "  inflating: Collection5/2007.ann    \n",
            "  inflating: Collection5/2007.txt    \n",
            "  inflating: Collection5/2008.ann    \n",
            "  inflating: Collection5/2008.txt    \n",
            "  inflating: Collection5/2009.ann    \n",
            "  inflating: Collection5/2009.txt    \n",
            "  inflating: Collection5/201.ann     \n",
            "  inflating: Collection5/201.txt     \n",
            "  inflating: Collection5/2010.ann    \n",
            "  inflating: Collection5/2010.txt    \n",
            "  inflating: Collection5/2011.ann    \n",
            "  inflating: Collection5/2011.txt    \n",
            "  inflating: Collection5/2012.ann    \n",
            "  inflating: Collection5/2012.txt    \n",
            "  inflating: Collection5/2013.ann    \n",
            "  inflating: Collection5/2013.txt    \n",
            "  inflating: Collection5/2014.ann    \n",
            "  inflating: Collection5/2014.txt    \n",
            "  inflating: Collection5/2015.ann    \n",
            "  inflating: Collection5/2015.txt    \n",
            "  inflating: Collection5/2016.ann    \n",
            "  inflating: Collection5/2016.txt    \n",
            "  inflating: Collection5/2017.ann    \n",
            "  inflating: Collection5/2017.txt    \n",
            "  inflating: Collection5/2018.ann    \n",
            "  inflating: Collection5/2018.txt    \n",
            "  inflating: Collection5/2019.ann    \n",
            "  inflating: Collection5/2019.txt    \n",
            "  inflating: Collection5/202.ann     \n",
            "  inflating: Collection5/202.txt     \n",
            "  inflating: Collection5/2020.ann    \n",
            "  inflating: Collection5/2020.txt    \n",
            "  inflating: Collection5/2021.ann    \n",
            "  inflating: Collection5/2021.txt    \n",
            "  inflating: Collection5/2022.ann    \n",
            "  inflating: Collection5/2022.txt    \n",
            "  inflating: Collection5/2023.ann    \n",
            "  inflating: Collection5/2023.txt    \n",
            "  inflating: Collection5/2024.ann    \n",
            "  inflating: Collection5/2024.txt    \n",
            "  inflating: Collection5/2025.ann    \n",
            "  inflating: Collection5/2025.txt    \n",
            "  inflating: Collection5/2026.ann    \n",
            "  inflating: Collection5/2026.txt    \n",
            "  inflating: Collection5/2027.ann    \n",
            "  inflating: Collection5/2027.txt    \n",
            "  inflating: Collection5/2028.ann    \n",
            "  inflating: Collection5/2028.txt    \n",
            "  inflating: Collection5/2029.ann    \n",
            "  inflating: Collection5/2029.txt    \n",
            "  inflating: Collection5/203.ann     \n",
            "  inflating: Collection5/203.txt     \n",
            "  inflating: Collection5/2030.ann    \n",
            "  inflating: Collection5/2030.txt    \n",
            "  inflating: Collection5/2031.ann    \n",
            "  inflating: Collection5/2031.txt    \n",
            "  inflating: Collection5/2032.ann    \n",
            "  inflating: Collection5/2032.txt    \n",
            "  inflating: Collection5/2034.ann    \n",
            "  inflating: Collection5/2034.txt    \n",
            "  inflating: Collection5/2035.ann    \n",
            "  inflating: Collection5/2035.txt    \n",
            "  inflating: Collection5/2036.ann    \n",
            "  inflating: Collection5/2036.txt    \n",
            "  inflating: Collection5/2037.ann    \n",
            "  inflating: Collection5/2037.txt    \n",
            "  inflating: Collection5/2038.ann    \n",
            "  inflating: Collection5/2038.txt    \n",
            "  inflating: Collection5/2039.ann    \n",
            "  inflating: Collection5/2039.txt    \n",
            "  inflating: Collection5/204.ann     \n",
            "  inflating: Collection5/204.txt     \n",
            "  inflating: Collection5/2040.ann    \n",
            "  inflating: Collection5/2040.txt    \n",
            "  inflating: Collection5/2041.ann    \n",
            "  inflating: Collection5/2041.txt    \n",
            "  inflating: Collection5/2042.ann    \n",
            "  inflating: Collection5/2042.txt    \n",
            "  inflating: Collection5/2043.ann    \n",
            "  inflating: Collection5/2043.txt    \n",
            "  inflating: Collection5/2044.ann    \n",
            "  inflating: Collection5/2044.txt    \n",
            "  inflating: Collection5/2045.ann    \n",
            "  inflating: Collection5/2045.txt    \n",
            "  inflating: Collection5/2046.ann    \n",
            "  inflating: Collection5/2046.txt    \n",
            "  inflating: Collection5/2047.ann    \n",
            "  inflating: Collection5/2047.txt    \n",
            "  inflating: Collection5/2048.ann    \n",
            "  inflating: Collection5/2048.txt    \n",
            "  inflating: Collection5/2049.ann    \n",
            "  inflating: Collection5/2049.txt    \n",
            "  inflating: Collection5/205.ann     \n",
            "  inflating: Collection5/205.txt     \n",
            "  inflating: Collection5/2050.ann    \n",
            "  inflating: Collection5/2050.txt    \n",
            "  inflating: Collection5/206.ann     \n",
            "  inflating: Collection5/206.txt     \n",
            "  inflating: Collection5/207.ann     \n",
            "  inflating: Collection5/207.txt     \n",
            "  inflating: Collection5/208.ann     \n",
            "  inflating: Collection5/208.txt     \n",
            "  inflating: Collection5/209.ann     \n",
            "  inflating: Collection5/209.txt     \n",
            "  inflating: Collection5/20_11_12a.ann  \n",
            "  inflating: Collection5/20_11_12a.txt  \n",
            "  inflating: Collection5/20_11_12b.ann  \n",
            "  inflating: Collection5/20_11_12b.txt  \n",
            "  inflating: Collection5/20_11_12c.ann  \n",
            "  inflating: Collection5/20_11_12c.txt  \n",
            "  inflating: Collection5/20_11_12d.ann  \n",
            "  inflating: Collection5/20_11_12d.txt  \n",
            "  inflating: Collection5/20_11_12i.ann  \n",
            "  inflating: Collection5/20_11_12i.txt  \n",
            "  inflating: Collection5/210.ann     \n",
            "  inflating: Collection5/210.txt     \n",
            "  inflating: Collection5/211.ann     \n",
            "  inflating: Collection5/211.txt     \n",
            "  inflating: Collection5/212.ann     \n",
            "  inflating: Collection5/212.txt     \n",
            "  inflating: Collection5/213.ann     \n",
            "  inflating: Collection5/213.txt     \n",
            "  inflating: Collection5/214.ann     \n",
            "  inflating: Collection5/214.txt     \n",
            "  inflating: Collection5/215.ann     \n",
            "  inflating: Collection5/215.txt     \n",
            "  inflating: Collection5/216.ann     \n",
            "  inflating: Collection5/216.txt     \n",
            "  inflating: Collection5/217.ann     \n",
            "  inflating: Collection5/217.txt     \n",
            "  inflating: Collection5/218.ann     \n",
            "  inflating: Collection5/218.txt     \n",
            "  inflating: Collection5/219.ann     \n",
            "  inflating: Collection5/219.txt     \n",
            "  inflating: Collection5/21_11_12c.ann  \n",
            "  inflating: Collection5/21_11_12c.txt  \n",
            "  inflating: Collection5/21_11_12h.ann  \n",
            "  inflating: Collection5/21_11_12h.txt  \n",
            "  inflating: Collection5/21_11_12i.ann  \n",
            "  inflating: Collection5/21_11_12i.txt  \n",
            "  inflating: Collection5/21_11_12j.ann  \n",
            "  inflating: Collection5/21_11_12j.txt  \n",
            "  inflating: Collection5/220.ann     \n",
            "  inflating: Collection5/220.txt     \n",
            "  inflating: Collection5/221.ann     \n",
            "  inflating: Collection5/221.txt     \n",
            "  inflating: Collection5/222.ann     \n",
            "  inflating: Collection5/222.txt     \n",
            "  inflating: Collection5/223.ann     \n",
            "  inflating: Collection5/223.txt     \n",
            "  inflating: Collection5/224.ann     \n",
            "  inflating: Collection5/224.txt     \n",
            "  inflating: Collection5/225.ann     \n",
            "  inflating: Collection5/225.txt     \n",
            "  inflating: Collection5/226.ann     \n",
            "  inflating: Collection5/226.txt     \n",
            "  inflating: Collection5/227.ann     \n",
            "  inflating: Collection5/227.txt     \n",
            "  inflating: Collection5/228.ann     \n",
            "  inflating: Collection5/228.txt     \n",
            "  inflating: Collection5/229.ann     \n",
            "  inflating: Collection5/229.txt     \n",
            "  inflating: Collection5/22_11_12a.ann  \n",
            "  inflating: Collection5/22_11_12a.txt  \n",
            "  inflating: Collection5/22_11_12c.ann  \n",
            "  inflating: Collection5/22_11_12c.txt  \n",
            "  inflating: Collection5/22_11_12d.ann  \n",
            "  inflating: Collection5/22_11_12d.txt  \n",
            "  inflating: Collection5/22_11_12g.ann  \n",
            "  inflating: Collection5/22_11_12g.txt  \n",
            "  inflating: Collection5/22_11_12h.ann  \n",
            "  inflating: Collection5/22_11_12h.txt  \n",
            "  inflating: Collection5/22_11_12i.ann  \n",
            "  inflating: Collection5/22_11_12i.txt  \n",
            "  inflating: Collection5/22_11_12j.ann  \n",
            "  inflating: Collection5/22_11_12j.txt  \n",
            "  inflating: Collection5/230.ann     \n",
            "  inflating: Collection5/230.txt     \n",
            "  inflating: Collection5/231.ann     \n",
            "  inflating: Collection5/231.txt     \n",
            "  inflating: Collection5/232.ann     \n",
            "  inflating: Collection5/232.txt     \n",
            "  inflating: Collection5/233.ann     \n",
            "  inflating: Collection5/233.txt     \n",
            "  inflating: Collection5/234.ann     \n",
            "  inflating: Collection5/234.txt     \n",
            "  inflating: Collection5/235.ann     \n",
            "  inflating: Collection5/235.txt     \n",
            "  inflating: Collection5/236.ann     \n",
            "  inflating: Collection5/236.txt     \n",
            "  inflating: Collection5/237.ann     \n",
            "  inflating: Collection5/237.txt     \n",
            "  inflating: Collection5/238.ann     \n",
            "  inflating: Collection5/238.txt     \n",
            "  inflating: Collection5/239.ann     \n",
            "  inflating: Collection5/239.txt     \n",
            "  inflating: Collection5/23_11_12a.ann  \n",
            "  inflating: Collection5/23_11_12a.txt  \n",
            "  inflating: Collection5/23_11_12b.ann  \n",
            "  inflating: Collection5/23_11_12b.txt  \n",
            "  inflating: Collection5/23_11_12c.ann  \n",
            "  inflating: Collection5/23_11_12c.txt  \n",
            "  inflating: Collection5/23_11_12d.ann  \n",
            "  inflating: Collection5/23_11_12d.txt  \n",
            "  inflating: Collection5/23_11_12e.ann  \n",
            "  inflating: Collection5/23_11_12e.txt  \n",
            "  inflating: Collection5/23_11_12f.ann  \n",
            "  inflating: Collection5/23_11_12f.txt  \n",
            "  inflating: Collection5/240.ann     \n",
            "  inflating: Collection5/240.txt     \n",
            "  inflating: Collection5/241.ann     \n",
            "  inflating: Collection5/241.txt     \n",
            "  inflating: Collection5/242.ann     \n",
            "  inflating: Collection5/242.txt     \n",
            "  inflating: Collection5/243.ann     \n",
            "  inflating: Collection5/243.txt     \n",
            "  inflating: Collection5/244.ann     \n",
            "  inflating: Collection5/244.txt     \n",
            "  inflating: Collection5/245.ann     \n",
            "  inflating: Collection5/245.txt     \n",
            "  inflating: Collection5/246.ann     \n",
            "  inflating: Collection5/246.txt     \n",
            "  inflating: Collection5/247.ann     \n",
            "  inflating: Collection5/247.txt     \n",
            "  inflating: Collection5/248.ann     \n",
            "  inflating: Collection5/248.txt     \n",
            "  inflating: Collection5/249.ann     \n",
            "  inflating: Collection5/249.txt     \n",
            "  inflating: Collection5/250.ann     \n",
            "  inflating: Collection5/250.txt     \n",
            "  inflating: Collection5/251.ann     \n",
            "  inflating: Collection5/251.txt     \n",
            "  inflating: Collection5/252.ann     \n",
            "  inflating: Collection5/252.txt     \n",
            "  inflating: Collection5/253.ann     \n",
            "  inflating: Collection5/253.txt     \n",
            "  inflating: Collection5/254.ann     \n",
            "  inflating: Collection5/254.txt     \n",
            "  inflating: Collection5/255.ann     \n",
            "  inflating: Collection5/255.txt     \n",
            "  inflating: Collection5/256.ann     \n",
            "  inflating: Collection5/256.txt     \n",
            "  inflating: Collection5/257.ann     \n",
            "  inflating: Collection5/257.txt     \n",
            "  inflating: Collection5/258.ann     \n",
            "  inflating: Collection5/258.txt     \n",
            "  inflating: Collection5/259.ann     \n",
            "  inflating: Collection5/259.txt     \n",
            "  inflating: Collection5/25_12_12a.ann  \n",
            "  inflating: Collection5/25_12_12a.txt  \n",
            "  inflating: Collection5/25_12_12c.ann  \n",
            "  inflating: Collection5/25_12_12c.txt  \n",
            "  inflating: Collection5/25_12_12d.ann  \n",
            "  inflating: Collection5/25_12_12d.txt  \n",
            "  inflating: Collection5/25_12_12e.ann  \n",
            "  inflating: Collection5/25_12_12e.txt  \n",
            "  inflating: Collection5/260.ann     \n",
            "  inflating: Collection5/260.txt     \n",
            "  inflating: Collection5/261.ann     \n",
            "  inflating: Collection5/261.txt     \n",
            "  inflating: Collection5/262.ann     \n",
            "  inflating: Collection5/262.txt     \n",
            "  inflating: Collection5/263.ann     \n",
            "  inflating: Collection5/263.txt     \n",
            "  inflating: Collection5/264.ann     \n",
            "  inflating: Collection5/264.txt     \n",
            "  inflating: Collection5/265.ann     \n",
            "  inflating: Collection5/265.txt     \n",
            "  inflating: Collection5/266.ann     \n",
            "  inflating: Collection5/266.txt     \n",
            "  inflating: Collection5/267.ann     \n",
            "  inflating: Collection5/267.txt     \n",
            "  inflating: Collection5/268.ann     \n",
            "  inflating: Collection5/268.txt     \n",
            "  inflating: Collection5/269.ann     \n",
            "  inflating: Collection5/269.txt     \n",
            "  inflating: Collection5/26_11_12b.ann  \n",
            "  inflating: Collection5/26_11_12b.txt  \n",
            "  inflating: Collection5/26_11_12c.ann  \n",
            "  inflating: Collection5/26_11_12c.txt  \n",
            "  inflating: Collection5/26_11_12e.ann  \n",
            "  inflating: Collection5/26_11_12e.txt  \n",
            "  inflating: Collection5/26_11_12f.ann  \n",
            "  inflating: Collection5/26_11_12f.txt  \n",
            "  inflating: Collection5/270.ann     \n",
            "  inflating: Collection5/270.txt     \n",
            "  inflating: Collection5/271.ann     \n",
            "  inflating: Collection5/271.txt     \n",
            "  inflating: Collection5/272.ann     \n",
            "  inflating: Collection5/272.txt     \n",
            "  inflating: Collection5/273.ann     \n",
            "  inflating: Collection5/273.txt     \n",
            "  inflating: Collection5/274.ann     \n",
            "  inflating: Collection5/274.txt     \n",
            "  inflating: Collection5/275.ann     \n",
            "  inflating: Collection5/275.txt     \n",
            "  inflating: Collection5/276.ann     \n",
            "  inflating: Collection5/276.txt     \n",
            "  inflating: Collection5/277.ann     \n",
            "  inflating: Collection5/277.txt     \n",
            "  inflating: Collection5/278.ann     \n",
            "  inflating: Collection5/278.txt     \n",
            "  inflating: Collection5/279.ann     \n",
            "  inflating: Collection5/279.txt     \n",
            "  inflating: Collection5/27_11_12a.ann  \n",
            "  inflating: Collection5/27_11_12a.txt  \n",
            "  inflating: Collection5/27_11_12c.ann  \n",
            "  inflating: Collection5/27_11_12c.txt  \n",
            "  inflating: Collection5/27_11_12d.ann  \n",
            "  inflating: Collection5/27_11_12d.txt  \n",
            "  inflating: Collection5/27_11_12e.ann  \n",
            "  inflating: Collection5/27_11_12e.txt  \n",
            "  inflating: Collection5/27_11_12j.ann  \n",
            "  inflating: Collection5/27_11_12j.txt  \n",
            "  inflating: Collection5/280.ann     \n",
            "  inflating: Collection5/280.txt     \n",
            "  inflating: Collection5/281.ann     \n",
            "  inflating: Collection5/281.txt     \n",
            "  inflating: Collection5/282.ann     \n",
            "  inflating: Collection5/282.txt     \n",
            "  inflating: Collection5/283.ann     \n",
            "  inflating: Collection5/283.txt     \n",
            "  inflating: Collection5/284.ann     \n",
            "  inflating: Collection5/284.txt     \n",
            "  inflating: Collection5/285.ann     \n",
            "  inflating: Collection5/285.txt     \n",
            "  inflating: Collection5/286.ann     \n",
            "  inflating: Collection5/286.txt     \n",
            "  inflating: Collection5/287.ann     \n",
            "  inflating: Collection5/287.txt     \n",
            "  inflating: Collection5/288.ann     \n",
            "  inflating: Collection5/288.txt     \n",
            "  inflating: Collection5/289.ann     \n",
            "  inflating: Collection5/289.txt     \n",
            "  inflating: Collection5/28_11_12a.ann  \n",
            "  inflating: Collection5/28_11_12a.txt  \n",
            "  inflating: Collection5/28_11_12f.ann  \n",
            "  inflating: Collection5/28_11_12f.txt  \n",
            "  inflating: Collection5/28_11_12g.ann  \n",
            "  inflating: Collection5/28_11_12g.txt  \n",
            "  inflating: Collection5/28_11_12h.ann  \n",
            "  inflating: Collection5/28_11_12h.txt  \n",
            "  inflating: Collection5/28_11_12i.ann  \n",
            "  inflating: Collection5/28_11_12i.txt  \n",
            "  inflating: Collection5/28_11_12j.ann  \n",
            "  inflating: Collection5/28_11_12j.txt  \n",
            "  inflating: Collection5/290.ann     \n",
            "  inflating: Collection5/290.txt     \n",
            "  inflating: Collection5/291.ann     \n",
            "  inflating: Collection5/291.txt     \n",
            "  inflating: Collection5/292.ann     \n",
            "  inflating: Collection5/292.txt     \n",
            "  inflating: Collection5/293.ann     \n",
            "  inflating: Collection5/293.txt     \n",
            "  inflating: Collection5/294.ann     \n",
            "  inflating: Collection5/294.txt     \n",
            "  inflating: Collection5/295.ann     \n",
            "  inflating: Collection5/295.txt     \n",
            "  inflating: Collection5/296.ann     \n",
            "  inflating: Collection5/296.txt     \n",
            "  inflating: Collection5/297.ann     \n",
            "  inflating: Collection5/297.txt     \n",
            "  inflating: Collection5/298.ann     \n",
            "  inflating: Collection5/298.txt     \n",
            "  inflating: Collection5/299.ann     \n",
            "  inflating: Collection5/299.txt     \n",
            "  inflating: Collection5/29_11_12a.ann  \n",
            "  inflating: Collection5/29_11_12a.txt  \n",
            "  inflating: Collection5/29_11_12b.ann  \n",
            "  inflating: Collection5/29_11_12b.txt  \n",
            "  inflating: Collection5/300.ann     \n",
            "  inflating: Collection5/300.txt     \n",
            "  inflating: Collection5/301.ann     \n",
            "  inflating: Collection5/301.txt     \n",
            "  inflating: Collection5/302.ann     \n",
            "  inflating: Collection5/302.txt     \n",
            "  inflating: Collection5/303.ann     \n",
            "  inflating: Collection5/303.txt     \n",
            "  inflating: Collection5/304.ann     \n",
            "  inflating: Collection5/304.txt     \n",
            "  inflating: Collection5/305.ann     \n",
            "  inflating: Collection5/305.txt     \n",
            "  inflating: Collection5/306.ann     \n",
            "  inflating: Collection5/306.txt     \n",
            "  inflating: Collection5/307.ann     \n",
            "  inflating: Collection5/307.txt     \n",
            "  inflating: Collection5/308.ann     \n",
            "  inflating: Collection5/308.txt     \n",
            "  inflating: Collection5/309.ann     \n",
            "  inflating: Collection5/309.txt     \n",
            "  inflating: Collection5/30_11_12b.ann  \n",
            "  inflating: Collection5/30_11_12b.txt  \n",
            "  inflating: Collection5/30_11_12h.ann  \n",
            "  inflating: Collection5/30_11_12h.txt  \n",
            "  inflating: Collection5/30_11_12i.ann  \n",
            "  inflating: Collection5/30_11_12i.txt  \n",
            "  inflating: Collection5/310.ann     \n",
            "  inflating: Collection5/310.txt     \n",
            "  inflating: Collection5/311.ann     \n",
            "  inflating: Collection5/311.txt     \n",
            "  inflating: Collection5/312.ann     \n",
            "  inflating: Collection5/312.txt     \n",
            "  inflating: Collection5/313.ann     \n",
            "  inflating: Collection5/313.txt     \n",
            "  inflating: Collection5/314.ann     \n",
            "  inflating: Collection5/314.txt     \n",
            "  inflating: Collection5/315.ann     \n",
            "  inflating: Collection5/315.txt     \n",
            "  inflating: Collection5/316.ann     \n",
            "  inflating: Collection5/316.txt     \n",
            "  inflating: Collection5/317.ann     \n",
            "  inflating: Collection5/317.txt     \n",
            "  inflating: Collection5/318.ann     \n",
            "  inflating: Collection5/318.txt     \n",
            "  inflating: Collection5/319.ann     \n",
            "  inflating: Collection5/319.txt     \n",
            "  inflating: Collection5/320.ann     \n",
            "  inflating: Collection5/320.txt     \n",
            "  inflating: Collection5/321.ann     \n",
            "  inflating: Collection5/321.txt     \n",
            "  inflating: Collection5/322.ann     \n",
            "  inflating: Collection5/322.txt     \n",
            "  inflating: Collection5/323.ann     \n",
            "  inflating: Collection5/323.txt     \n",
            "  inflating: Collection5/324.ann     \n",
            "  inflating: Collection5/324.txt     \n",
            "  inflating: Collection5/325.ann     \n",
            "  inflating: Collection5/325.txt     \n",
            "  inflating: Collection5/326.ann     \n",
            "  inflating: Collection5/326.txt     \n",
            "  inflating: Collection5/327.ann     \n",
            "  inflating: Collection5/327.txt     \n",
            "  inflating: Collection5/328.ann     \n",
            "  inflating: Collection5/328.txt     \n",
            "  inflating: Collection5/329.ann     \n",
            "  inflating: Collection5/329.txt     \n",
            "  inflating: Collection5/330.ann     \n",
            "  inflating: Collection5/330.txt     \n",
            "  inflating: Collection5/331.ann     \n",
            "  inflating: Collection5/331.txt     \n",
            "  inflating: Collection5/332.ann     \n",
            "  inflating: Collection5/332.txt     \n",
            "  inflating: Collection5/333.ann     \n",
            "  inflating: Collection5/333.txt     \n",
            "  inflating: Collection5/334.ann     \n",
            "  inflating: Collection5/334.txt     \n",
            "  inflating: Collection5/335.ann     \n",
            "  inflating: Collection5/335.txt     \n",
            "  inflating: Collection5/336.ann     \n",
            "  inflating: Collection5/336.txt     \n",
            "  inflating: Collection5/337.ann     \n",
            "  inflating: Collection5/337.txt     \n",
            "  inflating: Collection5/338.ann     \n",
            "  inflating: Collection5/338.txt     \n",
            "  inflating: Collection5/339.ann     \n",
            "  inflating: Collection5/339.txt     \n",
            "  inflating: Collection5/340.ann     \n",
            "  inflating: Collection5/340.txt     \n",
            "  inflating: Collection5/341.ann     \n",
            "  inflating: Collection5/341.txt     \n",
            "  inflating: Collection5/342.ann     \n",
            "  inflating: Collection5/342.txt     \n",
            "  inflating: Collection5/343.ann     \n",
            "  inflating: Collection5/343.txt     \n",
            "  inflating: Collection5/344.ann     \n",
            "  inflating: Collection5/344.txt     \n",
            "  inflating: Collection5/345.ann     \n",
            "  inflating: Collection5/345.txt     \n",
            "  inflating: Collection5/346.ann     \n",
            "  inflating: Collection5/346.txt     \n",
            "  inflating: Collection5/347.ann     \n",
            "  inflating: Collection5/347.txt     \n",
            "  inflating: Collection5/348.ann     \n",
            "  inflating: Collection5/348.txt     \n",
            "  inflating: Collection5/349.ann     \n",
            "  inflating: Collection5/349.txt     \n",
            "  inflating: Collection5/350.ann     \n",
            "  inflating: Collection5/350.txt     \n",
            "  inflating: Collection5/351.ann     \n",
            "  inflating: Collection5/351.txt     \n",
            "  inflating: Collection5/352.ann     \n",
            "  inflating: Collection5/352.txt     \n",
            "  inflating: Collection5/353.ann     \n",
            "  inflating: Collection5/353.txt     \n",
            "  inflating: Collection5/354.ann     \n",
            "  inflating: Collection5/354.txt     \n",
            "  inflating: Collection5/355.ann     \n",
            "  inflating: Collection5/355.txt     \n",
            "  inflating: Collection5/356.ann     \n",
            "  inflating: Collection5/356.txt     \n",
            "  inflating: Collection5/357.ann     \n",
            "  inflating: Collection5/357.txt     \n",
            "  inflating: Collection5/358.ann     \n",
            "  inflating: Collection5/358.txt     \n",
            "  inflating: Collection5/359.ann     \n",
            "  inflating: Collection5/359.txt     \n",
            "  inflating: Collection5/360.ann     \n",
            "  inflating: Collection5/360.txt     \n",
            "  inflating: Collection5/361.ann     \n",
            "  inflating: Collection5/361.txt     \n",
            "  inflating: Collection5/362.ann     \n",
            "  inflating: Collection5/362.txt     \n",
            "  inflating: Collection5/363.ann     \n",
            "  inflating: Collection5/363.txt     \n",
            "  inflating: Collection5/364.ann     \n",
            "  inflating: Collection5/364.txt     \n",
            "  inflating: Collection5/365.ann     \n",
            "  inflating: Collection5/365.txt     \n",
            "  inflating: Collection5/366.ann     \n",
            "  inflating: Collection5/366.txt     \n",
            "  inflating: Collection5/367.ann     \n",
            "  inflating: Collection5/367.txt     \n",
            "  inflating: Collection5/368.ann     \n",
            "  inflating: Collection5/368.txt     \n",
            "  inflating: Collection5/369.ann     \n",
            "  inflating: Collection5/369.txt     \n",
            "  inflating: Collection5/370.ann     \n",
            "  inflating: Collection5/370.txt     \n",
            "  inflating: Collection5/371.ann     \n",
            "  inflating: Collection5/371.txt     \n",
            "  inflating: Collection5/372.ann     \n",
            "  inflating: Collection5/372.txt     \n",
            "  inflating: Collection5/373.ann     \n",
            "  inflating: Collection5/373.txt     \n",
            "  inflating: Collection5/374.ann     \n",
            "  inflating: Collection5/374.txt     \n",
            "  inflating: Collection5/375.ann     \n",
            "  inflating: Collection5/375.txt     \n",
            "  inflating: Collection5/376.ann     \n",
            "  inflating: Collection5/376.txt     \n",
            "  inflating: Collection5/377.ann     \n",
            "  inflating: Collection5/377.txt     \n",
            "  inflating: Collection5/378.ann     \n",
            "  inflating: Collection5/378.txt     \n",
            "  inflating: Collection5/379.ann     \n",
            "  inflating: Collection5/379.txt     \n",
            "  inflating: Collection5/380.ann     \n",
            "  inflating: Collection5/380.txt     \n",
            "  inflating: Collection5/381.ann     \n",
            "  inflating: Collection5/381.txt     \n",
            "  inflating: Collection5/382.ann     \n",
            "  inflating: Collection5/382.txt     \n",
            "  inflating: Collection5/383.ann     \n",
            "  inflating: Collection5/383.txt     \n",
            "  inflating: Collection5/384.ann     \n",
            "  inflating: Collection5/384.txt     \n",
            "  inflating: Collection5/385.ann     \n",
            "  inflating: Collection5/385.txt     \n",
            "  inflating: Collection5/386.ann     \n",
            "  inflating: Collection5/386.txt     \n",
            "  inflating: Collection5/387.ann     \n",
            "  inflating: Collection5/387.txt     \n",
            "  inflating: Collection5/388.ann     \n",
            "  inflating: Collection5/388.txt     \n",
            "  inflating: Collection5/389.ann     \n",
            "  inflating: Collection5/389.txt     \n",
            "  inflating: Collection5/390.ann     \n",
            "  inflating: Collection5/390.txt     \n",
            "  inflating: Collection5/391.ann     \n",
            "  inflating: Collection5/391.txt     \n",
            "  inflating: Collection5/392.ann     \n",
            "  inflating: Collection5/392.txt     \n",
            "  inflating: Collection5/393.ann     \n",
            "  inflating: Collection5/393.txt     \n",
            "  inflating: Collection5/394.ann     \n",
            "  inflating: Collection5/394.txt     \n",
            "  inflating: Collection5/395.ann     \n",
            "  inflating: Collection5/395.txt     \n",
            "  inflating: Collection5/396.ann     \n",
            "  inflating: Collection5/396.txt     \n",
            "  inflating: Collection5/397.ann     \n",
            "  inflating: Collection5/397.txt     \n",
            "  inflating: Collection5/398.ann     \n",
            "  inflating: Collection5/398.txt     \n",
            "  inflating: Collection5/399.ann     \n",
            "  inflating: Collection5/399.txt     \n",
            "  inflating: Collection5/400.ann     \n",
            "  inflating: Collection5/400.txt     \n",
            "  inflating: Collection5/401.ann     \n",
            "  inflating: Collection5/401.txt     \n",
            "  inflating: Collection5/402.ann     \n",
            "  inflating: Collection5/402.txt     \n",
            "  inflating: Collection5/403.ann     \n",
            "  inflating: Collection5/403.txt     \n",
            "  inflating: Collection5/404.ann     \n",
            "  inflating: Collection5/404.txt     \n",
            "  inflating: Collection5/405.ann     \n",
            "  inflating: Collection5/405.txt     \n",
            "  inflating: Collection5/406.ann     \n",
            "  inflating: Collection5/406.txt     \n",
            "  inflating: Collection5/407.ann     \n",
            "  inflating: Collection5/407.txt     \n",
            "  inflating: Collection5/408.ann     \n",
            "  inflating: Collection5/408.txt     \n",
            "  inflating: Collection5/409.ann     \n",
            "  inflating: Collection5/409.txt     \n",
            "  inflating: Collection5/410.ann     \n",
            "  inflating: Collection5/410.txt     \n",
            "  inflating: Collection5/411.ann     \n",
            "  inflating: Collection5/411.txt     \n",
            "  inflating: Collection5/412.ann     \n",
            "  inflating: Collection5/412.txt     \n",
            "  inflating: Collection5/413.ann     \n",
            "  inflating: Collection5/413.txt     \n",
            "  inflating: Collection5/414.ann     \n",
            "  inflating: Collection5/414.txt     \n",
            "  inflating: Collection5/415.ann     \n",
            "  inflating: Collection5/415.txt     \n",
            "  inflating: Collection5/416.ann     \n",
            "  inflating: Collection5/416.txt     \n",
            "  inflating: Collection5/417.ann     \n",
            "  inflating: Collection5/417.txt     \n",
            "  inflating: Collection5/418.ann     \n",
            "  inflating: Collection5/418.txt     \n",
            "  inflating: Collection5/419.ann     \n",
            "  inflating: Collection5/419.txt     \n",
            "  inflating: Collection5/420.ann     \n",
            "  inflating: Collection5/420.txt     \n",
            "  inflating: Collection5/421.ann     \n",
            "  inflating: Collection5/421.txt     \n",
            "  inflating: Collection5/422.ann     \n",
            "  inflating: Collection5/422.txt     \n",
            "  inflating: Collection5/423.ann     \n",
            "  inflating: Collection5/423.txt     \n",
            "  inflating: Collection5/424.ann     \n",
            "  inflating: Collection5/424.txt     \n",
            "  inflating: Collection5/425.ann     \n",
            "  inflating: Collection5/425.txt     \n",
            "  inflating: Collection5/426.ann     \n",
            "  inflating: Collection5/426.txt     \n",
            "  inflating: Collection5/427.ann     \n",
            "  inflating: Collection5/427.txt     \n",
            "  inflating: Collection5/428.ann     \n",
            "  inflating: Collection5/428.txt     \n",
            "  inflating: Collection5/429.ann     \n",
            "  inflating: Collection5/429.txt     \n",
            "  inflating: Collection5/430.ann     \n",
            "  inflating: Collection5/430.txt     \n",
            "  inflating: Collection5/431.ann     \n",
            "  inflating: Collection5/431.txt     \n",
            "  inflating: Collection5/432.ann     \n",
            "  inflating: Collection5/432.txt     \n",
            "  inflating: Collection5/433.ann     \n",
            "  inflating: Collection5/433.txt     \n",
            "  inflating: Collection5/434.ann     \n",
            "  inflating: Collection5/434.txt     \n",
            "  inflating: Collection5/435.ann     \n",
            "  inflating: Collection5/435.txt     \n",
            "  inflating: Collection5/436.ann     \n",
            "  inflating: Collection5/436.txt     \n",
            "  inflating: Collection5/437.ann     \n",
            "  inflating: Collection5/437.txt     \n",
            "  inflating: Collection5/438.ann     \n",
            "  inflating: Collection5/438.txt     \n",
            "  inflating: Collection5/439.ann     \n",
            "  inflating: Collection5/439.txt     \n",
            "  inflating: Collection5/440.ann     \n",
            "  inflating: Collection5/440.txt     \n",
            "  inflating: Collection5/441.ann     \n",
            "  inflating: Collection5/441.txt     \n",
            "  inflating: Collection5/442.ann     \n",
            "  inflating: Collection5/442.txt     \n",
            "  inflating: Collection5/443.ann     \n",
            "  inflating: Collection5/443.txt     \n",
            "  inflating: Collection5/444.ann     \n",
            "  inflating: Collection5/444.txt     \n",
            "  inflating: Collection5/445.ann     \n",
            "  inflating: Collection5/445.txt     \n",
            "  inflating: Collection5/446.ann     \n",
            "  inflating: Collection5/446.txt     \n",
            "  inflating: Collection5/447.ann     \n",
            "  inflating: Collection5/447.txt     \n",
            "  inflating: Collection5/448.ann     \n",
            "  inflating: Collection5/448.txt     \n",
            "  inflating: Collection5/449.ann     \n",
            "  inflating: Collection5/449.txt     \n",
            "  inflating: Collection5/450.ann     \n",
            "  inflating: Collection5/450.txt     \n",
            "  inflating: Collection5/451.ann     \n",
            "  inflating: Collection5/451.txt     \n",
            "  inflating: Collection5/452.ann     \n",
            "  inflating: Collection5/452.txt     \n",
            "  inflating: Collection5/453.ann     \n",
            "  inflating: Collection5/453.txt     \n",
            "  inflating: Collection5/454.ann     \n",
            "  inflating: Collection5/454.txt     \n",
            "  inflating: Collection5/455.ann     \n",
            "  inflating: Collection5/455.txt     \n",
            "  inflating: Collection5/457.ann     \n",
            "  inflating: Collection5/457.txt     \n",
            "  inflating: Collection5/458.ann     \n",
            "  inflating: Collection5/458.txt     \n",
            "  inflating: Collection5/459.ann     \n",
            "  inflating: Collection5/459.txt     \n",
            "  inflating: Collection5/460.ann     \n",
            "  inflating: Collection5/460.txt     \n",
            "  inflating: Collection5/461.ann     \n",
            "  inflating: Collection5/461.txt     \n",
            "  inflating: Collection5/462.ann     \n",
            "  inflating: Collection5/462.txt     \n",
            "  inflating: Collection5/463.ann     \n",
            "  inflating: Collection5/463.txt     \n",
            "  inflating: Collection5/464.ann     \n",
            "  inflating: Collection5/464.txt     \n",
            "  inflating: Collection5/465.ann     \n",
            "  inflating: Collection5/465.txt     \n",
            "  inflating: Collection5/466.ann     \n",
            "  inflating: Collection5/466.txt     \n",
            "  inflating: Collection5/467.ann     \n",
            "  inflating: Collection5/467.txt     \n",
            "  inflating: Collection5/468.ann     \n",
            "  inflating: Collection5/468.txt     \n",
            "  inflating: Collection5/469.ann     \n",
            "  inflating: Collection5/469.txt     \n",
            "  inflating: Collection5/470.ann     \n",
            "  inflating: Collection5/470.txt     \n",
            "  inflating: Collection5/471.ann     \n",
            "  inflating: Collection5/471.txt     \n",
            "  inflating: Collection5/472.ann     \n",
            "  inflating: Collection5/472.txt     \n",
            "  inflating: Collection5/473.ann     \n",
            "  inflating: Collection5/473.txt     \n",
            "  inflating: Collection5/474.ann     \n",
            "  inflating: Collection5/474.txt     \n",
            "  inflating: Collection5/475.ann     \n",
            "  inflating: Collection5/475.txt     \n",
            "  inflating: Collection5/476.ann     \n",
            "  inflating: Collection5/476.txt     \n",
            "  inflating: Collection5/477.ann     \n",
            "  inflating: Collection5/477.txt     \n",
            "  inflating: Collection5/478.ann     \n",
            "  inflating: Collection5/478.txt     \n",
            "  inflating: Collection5/479.ann     \n",
            "  inflating: Collection5/479.txt     \n",
            "  inflating: Collection5/480.ann     \n",
            "  inflating: Collection5/480.txt     \n",
            "  inflating: Collection5/481.ann     \n",
            "  inflating: Collection5/481.txt     \n",
            "  inflating: Collection5/482.ann     \n",
            "  inflating: Collection5/482.txt     \n",
            "  inflating: Collection5/483.ann     \n",
            "  inflating: Collection5/483.txt     \n",
            "  inflating: Collection5/484.ann     \n",
            "  inflating: Collection5/484.txt     \n",
            "  inflating: Collection5/485.ann     \n",
            "  inflating: Collection5/485.txt     \n",
            "  inflating: Collection5/486.ann     \n",
            "  inflating: Collection5/486.txt     \n",
            "  inflating: Collection5/487.ann     \n",
            "  inflating: Collection5/487.txt     \n",
            "  inflating: Collection5/488.ann     \n",
            "  inflating: Collection5/488.txt     \n",
            "  inflating: Collection5/489.ann     \n",
            "  inflating: Collection5/489.txt     \n",
            "  inflating: Collection5/490.ann     \n",
            "  inflating: Collection5/490.txt     \n",
            "  inflating: Collection5/491.ann     \n",
            "  inflating: Collection5/491.txt     \n",
            "  inflating: Collection5/492.ann     \n",
            "  inflating: Collection5/492.txt     \n",
            "  inflating: Collection5/493.ann     \n",
            "  inflating: Collection5/493.txt     \n",
            "  inflating: Collection5/494.ann     \n",
            "  inflating: Collection5/494.txt     \n",
            "  inflating: Collection5/495.ann     \n",
            "  inflating: Collection5/495.txt     \n",
            "  inflating: Collection5/496.ann     \n",
            "  inflating: Collection5/496.txt     \n",
            "  inflating: Collection5/497.ann     \n",
            "  inflating: Collection5/497.txt     \n",
            "  inflating: Collection5/498.ann     \n",
            "  inflating: Collection5/498.txt     \n",
            "  inflating: Collection5/499.ann     \n",
            "  inflating: Collection5/499.txt     \n",
            "  inflating: Collection5/500.ann     \n",
            "  inflating: Collection5/500.txt     \n",
            "  inflating: Collection5/501.ann     \n",
            "  inflating: Collection5/501.txt     \n",
            "  inflating: Collection5/502.ann     \n",
            "  inflating: Collection5/502.txt     \n",
            "  inflating: Collection5/503.ann     \n",
            "  inflating: Collection5/503.txt     \n",
            "  inflating: Collection5/504.ann     \n",
            "  inflating: Collection5/504.txt     \n",
            "  inflating: Collection5/505.ann     \n",
            "  inflating: Collection5/505.txt     \n",
            "  inflating: Collection5/506.ann     \n",
            "  inflating: Collection5/506.txt     \n",
            "  inflating: Collection5/507.ann     \n",
            "  inflating: Collection5/507.txt     \n",
            "  inflating: Collection5/508.ann     \n",
            "  inflating: Collection5/508.txt     \n",
            "  inflating: Collection5/509.ann     \n",
            "  inflating: Collection5/509.txt     \n",
            "  inflating: Collection5/510.ann     \n",
            "  inflating: Collection5/510.txt     \n",
            "  inflating: Collection5/511.ann     \n",
            "  inflating: Collection5/511.txt     \n",
            "  inflating: Collection5/512.ann     \n",
            "  inflating: Collection5/512.txt     \n",
            "  inflating: Collection5/513.ann     \n",
            "  inflating: Collection5/513.txt     \n",
            "  inflating: Collection5/514.ann     \n",
            "  inflating: Collection5/514.txt     \n",
            "  inflating: Collection5/515.ann     \n",
            "  inflating: Collection5/515.txt     \n",
            "  inflating: Collection5/516.ann     \n",
            "  inflating: Collection5/516.txt     \n",
            "  inflating: Collection5/517.ann     \n",
            "  inflating: Collection5/517.txt     \n",
            "  inflating: Collection5/518.ann     \n",
            "  inflating: Collection5/518.txt     \n",
            "  inflating: Collection5/519.ann     \n",
            "  inflating: Collection5/519.txt     \n",
            "  inflating: Collection5/520.ann     \n",
            "  inflating: Collection5/520.txt     \n",
            "  inflating: Collection5/521.ann     \n",
            "  inflating: Collection5/521.txt     \n",
            "  inflating: Collection5/522.ann     \n",
            "  inflating: Collection5/522.txt     \n",
            "  inflating: Collection5/523.ann     \n",
            "  inflating: Collection5/523.txt     \n",
            "  inflating: Collection5/524.ann     \n",
            "  inflating: Collection5/524.txt     \n",
            "  inflating: Collection5/525.ann     \n",
            "  inflating: Collection5/525.txt     \n",
            "  inflating: Collection5/526.ann     \n",
            "  inflating: Collection5/526.txt     \n",
            "  inflating: Collection5/527.ann     \n",
            "  inflating: Collection5/527.txt     \n",
            "  inflating: Collection5/528.ann     \n",
            "  inflating: Collection5/528.txt     \n",
            "  inflating: Collection5/529.ann     \n",
            "  inflating: Collection5/529.txt     \n",
            "  inflating: Collection5/530.ann     \n",
            "  inflating: Collection5/530.txt     \n",
            "  inflating: Collection5/531.ann     \n",
            "  inflating: Collection5/531.txt     \n",
            "  inflating: Collection5/532.ann     \n",
            "  inflating: Collection5/532.txt     \n",
            "  inflating: Collection5/533 (!).ann  \n",
            "  inflating: Collection5/533 (!).txt  \n",
            "  inflating: Collection5/534.ann     \n",
            "  inflating: Collection5/534.txt     \n",
            "  inflating: Collection5/535.ann     \n",
            "  inflating: Collection5/535.txt     \n",
            "  inflating: Collection5/536.ann     \n",
            "  inflating: Collection5/536.txt     \n",
            "  inflating: Collection5/537.ann     \n",
            "  inflating: Collection5/537.txt     \n",
            "  inflating: Collection5/538.ann     \n",
            "  inflating: Collection5/538.txt     \n",
            "  inflating: Collection5/539.ann     \n",
            "  inflating: Collection5/539.txt     \n",
            "  inflating: Collection5/540.ann     \n",
            "  inflating: Collection5/540.txt     \n",
            "  inflating: Collection5/541.ann     \n",
            "  inflating: Collection5/541.txt     \n",
            "  inflating: Collection5/542.ann     \n",
            "  inflating: Collection5/542.txt     \n",
            "  inflating: Collection5/543.ann     \n",
            "  inflating: Collection5/543.txt     \n",
            "  inflating: Collection5/544.ann     \n",
            "  inflating: Collection5/544.txt     \n",
            "  inflating: Collection5/545.ann     \n",
            "  inflating: Collection5/545.txt     \n",
            "  inflating: Collection5/546.ann     \n",
            "  inflating: Collection5/546.txt     \n",
            "  inflating: Collection5/547.ann     \n",
            "  inflating: Collection5/547.txt     \n",
            "  inflating: Collection5/548.ann     \n",
            "  inflating: Collection5/548.txt     \n",
            "  inflating: Collection5/549.ann     \n",
            "  inflating: Collection5/549.txt     \n",
            "  inflating: Collection5/550.ann     \n",
            "  inflating: Collection5/550.txt     \n",
            "  inflating: Collection5/551.ann     \n",
            "  inflating: Collection5/551.txt     \n",
            "  inflating: Collection5/552.ann     \n",
            "  inflating: Collection5/552.txt     \n",
            "  inflating: Collection5/553.ann     \n",
            "  inflating: Collection5/553.txt     \n",
            "  inflating: Collection5/554.ann     \n",
            "  inflating: Collection5/554.txt     \n",
            "  inflating: Collection5/555 (!).ann  \n",
            "  inflating: Collection5/555 (!).txt  \n",
            "  inflating: Collection5/556.ann     \n",
            "  inflating: Collection5/556.txt     \n",
            "  inflating: Collection5/557.ann     \n",
            "  inflating: Collection5/557.txt     \n",
            "  inflating: Collection5/558.ann     \n",
            "  inflating: Collection5/558.txt     \n",
            "  inflating: Collection5/559.ann     \n",
            "  inflating: Collection5/559.txt     \n",
            "  inflating: Collection5/560.ann     \n",
            "  inflating: Collection5/560.txt     \n",
            "  inflating: Collection5/561.ann     \n",
            "  inflating: Collection5/561.txt     \n",
            "  inflating: Collection5/562.ann     \n",
            "  inflating: Collection5/562.txt     \n",
            "  inflating: Collection5/563.ann     \n",
            "  inflating: Collection5/563.txt     \n",
            "  inflating: Collection5/564.ann     \n",
            "  inflating: Collection5/564.txt     \n",
            "  inflating: Collection5/565.ann     \n",
            "  inflating: Collection5/565.txt     \n",
            "  inflating: Collection5/567.ann     \n",
            "  inflating: Collection5/567.txt     \n",
            "  inflating: Collection5/568.ann     \n",
            "  inflating: Collection5/568.txt     \n",
            "  inflating: Collection5/569.ann     \n",
            "  inflating: Collection5/569.txt     \n",
            "  inflating: Collection5/570.ann     \n",
            "  inflating: Collection5/570.txt     \n",
            "  inflating: Collection5/571.ann     \n",
            "  inflating: Collection5/571.txt     \n",
            "  inflating: Collection5/572.ann     \n",
            "  inflating: Collection5/572.txt     \n",
            "  inflating: Collection5/574.ann     \n",
            "  inflating: Collection5/574.txt     \n",
            "  inflating: Collection5/575.ann     \n",
            "  inflating: Collection5/575.txt     \n",
            "  inflating: Collection5/576.ann     \n",
            "  inflating: Collection5/576.txt     \n",
            "  inflating: Collection5/577.ann     \n",
            "  inflating: Collection5/577.txt     \n",
            "  inflating: Collection5/578.ann     \n",
            "  inflating: Collection5/578.txt     \n",
            "  inflating: Collection5/579.ann     \n",
            "  inflating: Collection5/579.txt     \n",
            "  inflating: Collection5/581.ann     \n",
            "  inflating: Collection5/581.txt     \n",
            "  inflating: Collection5/582.ann     \n",
            "  inflating: Collection5/582.txt     \n",
            "  inflating: Collection5/583.ann     \n",
            "  inflating: Collection5/583.txt     \n",
            "  inflating: Collection5/584 (!).ann  \n",
            "  inflating: Collection5/584 (!).txt  \n",
            "  inflating: Collection5/585.ann     \n",
            "  inflating: Collection5/585.txt     \n",
            "  inflating: Collection5/586.ann     \n",
            "  inflating: Collection5/586.txt     \n",
            "  inflating: Collection5/587.ann     \n",
            "  inflating: Collection5/587.txt     \n",
            "  inflating: Collection5/588.ann     \n",
            "  inflating: Collection5/588.txt     \n",
            "  inflating: Collection5/589.ann     \n",
            "  inflating: Collection5/589.txt     \n",
            "  inflating: Collection5/590.ann     \n",
            "  inflating: Collection5/590.txt     \n",
            "  inflating: Collection5/591.ann     \n",
            "  inflating: Collection5/591.txt     \n",
            "  inflating: Collection5/592.ann     \n",
            "  inflating: Collection5/592.txt     \n",
            "  inflating: Collection5/593.ann     \n",
            "  inflating: Collection5/593.txt     \n",
            "  inflating: Collection5/594.ann     \n",
            "  inflating: Collection5/594.txt     \n",
            "  inflating: Collection5/595.ann     \n",
            "  inflating: Collection5/595.txt     \n",
            "  inflating: Collection5/596.ann     \n",
            "  inflating: Collection5/596.txt     \n",
            "  inflating: Collection5/597.ann     \n",
            "  inflating: Collection5/597.txt     \n",
            "  inflating: Collection5/598 (!).ann  \n",
            "  inflating: Collection5/598 (!).txt  \n",
            "  inflating: Collection5/599.ann     \n",
            "  inflating: Collection5/599.txt     \n",
            "  inflating: Collection5/600.ann     \n",
            "  inflating: Collection5/600.txt     \n",
            "  inflating: Collection5/601.ann     \n",
            "  inflating: Collection5/601.txt     \n",
            "  inflating: Collection5/602.ann     \n",
            "  inflating: Collection5/602.txt     \n",
            "  inflating: Collection5/610.ann     \n",
            "  inflating: Collection5/610.txt     \n",
            "  inflating: Collection5/611.ann     \n",
            "  inflating: Collection5/611.txt     \n",
            "  inflating: Collection5/612.ann     \n",
            "  inflating: Collection5/612.txt     \n",
            "  inflating: Collection5/613.ann     \n",
            "  inflating: Collection5/613.txt     \n",
            "  inflating: Collection5/614.ann     \n",
            "  inflating: Collection5/614.txt     \n",
            "  inflating: Collection5/615.ann     \n",
            "  inflating: Collection5/615.txt     \n",
            "  inflating: Collection5/616.ann     \n",
            "  inflating: Collection5/616.txt     \n",
            "  inflating: Collection5/617.ann     \n",
            "  inflating: Collection5/617.txt     \n",
            "  inflating: Collection5/618.ann     \n",
            "  inflating: Collection5/618.txt     \n",
            "  inflating: Collection5/619.ann     \n",
            "  inflating: Collection5/619.txt     \n",
            "  inflating: Collection5/620.ann     \n",
            "  inflating: Collection5/620.txt     \n",
            "  inflating: Collection5/621.ann     \n",
            "  inflating: Collection5/621.txt     \n",
            "  inflating: Collection5/622.ann     \n",
            "  inflating: Collection5/622.txt     \n",
            "  inflating: Collection5/623.ann     \n",
            "  inflating: Collection5/623.txt     \n",
            "  inflating: Collection5/624.ann     \n",
            "  inflating: Collection5/624.txt     \n",
            "  inflating: Collection5/625.ann     \n",
            "  inflating: Collection5/625.txt     \n",
            "  inflating: Collection5/626.ann     \n",
            "  inflating: Collection5/626.txt     \n",
            "  inflating: Collection5/627.ann     \n",
            "  inflating: Collection5/627.txt     \n",
            "  inflating: Collection5/628.ann     \n",
            "  inflating: Collection5/628.txt     \n",
            "  inflating: Collection5/629.ann     \n",
            "  inflating: Collection5/629.txt     \n",
            "  inflating: Collection5/630.ann     \n",
            "  inflating: Collection5/630.txt     \n",
            "  inflating: Collection5/631.ann     \n",
            "  inflating: Collection5/631.txt     \n",
            "  inflating: Collection5/632.ann     \n",
            "  inflating: Collection5/632.txt     \n",
            "  inflating: Collection5/633.ann     \n",
            "  inflating: Collection5/633.txt     \n",
            "  inflating: Collection5/abdulatipov.ann  \n",
            "  inflating: Collection5/abdulatipov.txt  \n",
            "  inflating: Collection5/artjakov.ann  \n",
            "  inflating: Collection5/artjakov.txt  \n",
            "  inflating: Collection5/Avtovaz.ann  \n",
            "  inflating: Collection5/Avtovaz.txt  \n",
            "  inflating: Collection5/blokhin.ann  \n",
            "  inflating: Collection5/blokhin.txt  \n",
            "  inflating: Collection5/chaves.ann  \n",
            "  inflating: Collection5/chaves.txt  \n",
            "  inflating: Collection5/chirkunov.ann  \n",
            "  inflating: Collection5/chirkunov.txt  \n",
            "  inflating: Collection5/kamchatka.ann  \n",
            "  inflating: Collection5/kamchatka.txt  \n",
            "  inflating: Collection5/klinton.ann  \n",
            "  inflating: Collection5/klinton.txt  \n",
            "  inflating: Collection5/kuleshov.ann  \n",
            "  inflating: Collection5/kuleshov.txt  \n",
            "  inflating: Collection5/last_01.ann  \n",
            "  inflating: Collection5/last_01.txt  \n",
            "  inflating: Collection5/last_02.ann  \n",
            "  inflating: Collection5/last_02.txt  \n",
            "  inflating: Collection5/last_03.ann  \n",
            "  inflating: Collection5/last_03.txt  \n",
            "  inflating: Collection5/last_04.ann  \n",
            "  inflating: Collection5/last_04.txt  \n",
            "  inflating: Collection5/last_05.ann  \n",
            "  inflating: Collection5/last_05.txt  \n",
            "  inflating: Collection5/last_06.ann  \n",
            "  inflating: Collection5/last_06.txt  \n",
            "  inflating: Collection5/last_07_new.ann  \n",
            "  inflating: Collection5/last_07_new.txt  \n",
            "  inflating: Collection5/last_08.ann  \n",
            "  inflating: Collection5/last_08.txt  \n",
            "  inflating: Collection5/last_09.ann  \n",
            "  inflating: Collection5/last_09.txt  \n",
            "  inflating: Collection5/last_10.ann  \n",
            "  inflating: Collection5/last_10.txt  \n",
            "  inflating: Collection5/last_11.ann  \n",
            "  inflating: Collection5/last_11.txt  \n",
            "  inflating: Collection5/last_12.ann  \n",
            "  inflating: Collection5/last_12.txt  \n",
            "  inflating: Collection5/last_13.ann  \n",
            "  inflating: Collection5/last_13.txt  \n",
            "  inflating: Collection5/last_14.ann  \n",
            "  inflating: Collection5/last_14.txt  \n",
            "  inflating: Collection5/last_15.ann  \n",
            "  inflating: Collection5/last_15.txt  \n",
            "  inflating: Collection5/last_16.ann  \n",
            "  inflating: Collection5/last_16.txt  \n",
            "  inflating: Collection5/last_17.ann  \n",
            "  inflating: Collection5/last_17.txt  \n",
            "  inflating: Collection5/last_18.ann  \n",
            "  inflating: Collection5/last_18.txt  \n",
            "  inflating: Collection5/last_19.ann  \n",
            "  inflating: Collection5/last_19.txt  \n",
            "  inflating: Collection5/last_20.ann  \n",
            "  inflating: Collection5/last_20.txt  \n",
            "  inflating: Collection5/last_21.ann  \n",
            "  inflating: Collection5/last_21.txt  \n",
            "  inflating: Collection5/last_22.ann  \n",
            "  inflating: Collection5/last_22.txt  \n",
            "  inflating: Collection5/last_23.ann  \n",
            "  inflating: Collection5/last_23.txt  \n",
            "  inflating: Collection5/last_24.ann  \n",
            "  inflating: Collection5/last_24.txt  \n",
            "  inflating: Collection5/last_25.ann  \n",
            "  inflating: Collection5/last_25.txt  \n",
            "  inflating: Collection5/last_26.ann  \n",
            "  inflating: Collection5/last_26.txt  \n",
            "  inflating: Collection5/last_27.ann  \n",
            "  inflating: Collection5/last_27.txt  \n",
            "  inflating: Collection5/last_28.ann  \n",
            "  inflating: Collection5/last_28.txt  \n",
            "  inflating: Collection5/last_29.ann  \n",
            "  inflating: Collection5/last_29.txt  \n",
            "  inflating: Collection5/last_30_new.ann  \n",
            "  inflating: Collection5/last_30_new.txt  \n",
            "  inflating: Collection5/last_31.ann  \n",
            "  inflating: Collection5/last_31.txt  \n",
            "  inflating: Collection5/last_32.ann  \n",
            "  inflating: Collection5/last_32.txt  \n",
            "  inflating: Collection5/last_33.ann  \n",
            "  inflating: Collection5/last_33.txt  \n",
            "  inflating: Collection5/last_34.ann  \n",
            "  inflating: Collection5/last_34.txt  \n",
            "  inflating: Collection5/last_35.ann  \n",
            "  inflating: Collection5/last_35.txt  \n",
            "  inflating: Collection5/last_36.ann  \n",
            "  inflating: Collection5/last_36.txt  \n",
            "  inflating: Collection5/last_37.ann  \n",
            "  inflating: Collection5/last_37.txt  \n",
            "  inflating: Collection5/last_38.ann  \n",
            "  inflating: Collection5/last_38.txt  \n",
            "  inflating: Collection5/last_39.ann  \n",
            "  inflating: Collection5/last_39.txt  \n",
            "  inflating: Collection5/last_40.ann  \n",
            "  inflating: Collection5/last_40.txt  \n",
            "  inflating: Collection5/last_41.ann  \n",
            "  inflating: Collection5/last_41.txt  \n",
            "  inflating: Collection5/last_42.ann  \n",
            "  inflating: Collection5/last_42.txt  \n",
            "  inflating: Collection5/last_43.ann  \n",
            "  inflating: Collection5/last_43.txt  \n",
            "  inflating: Collection5/last_44.ann  \n",
            "  inflating: Collection5/last_44.txt  \n",
            "  inflating: Collection5/last_45.ann  \n",
            "  inflating: Collection5/last_45.txt  \n",
            "  inflating: Collection5/last_46.ann  \n",
            "  inflating: Collection5/last_46.txt  \n",
            "  inflating: Collection5/last_47.ann  \n",
            "  inflating: Collection5/last_47.txt  \n",
            "  inflating: Collection5/last_48.ann  \n",
            "  inflating: Collection5/last_48.txt  \n",
            "  inflating: Collection5/last_49.ann  \n",
            "  inflating: Collection5/last_49.txt  \n",
            "  inflating: Collection5/last_50.ann  \n",
            "  inflating: Collection5/last_50.txt  \n",
            "  inflating: Collection5/last_51.ann  \n",
            "  inflating: Collection5/last_51.txt  \n",
            "  inflating: Collection5/last_52.ann  \n",
            "  inflating: Collection5/last_52.txt  \n",
            "  inflating: Collection5/last_53.ann  \n",
            "  inflating: Collection5/last_53.txt  \n",
            "  inflating: Collection5/last_54.ann  \n",
            "  inflating: Collection5/last_54.txt  \n",
            "  inflating: Collection5/last_55.ann  \n",
            "  inflating: Collection5/last_55.txt  \n",
            "  inflating: Collection5/last_56.ann  \n",
            "  inflating: Collection5/last_56.txt  \n",
            "  inflating: Collection5/last_57.ann  \n",
            "  inflating: Collection5/last_57.txt  \n",
            "  inflating: Collection5/last_58.ann  \n",
            "  inflating: Collection5/last_58.txt  \n",
            "  inflating: Collection5/last_59.ann  \n",
            "  inflating: Collection5/last_59.txt  \n",
            "  inflating: Collection5/last_60.ann  \n",
            "  inflating: Collection5/last_60.txt  \n",
            "  inflating: Collection5/last_61.ann  \n",
            "  inflating: Collection5/last_61.txt  \n",
            "  inflating: Collection5/last_62.ann  \n",
            "  inflating: Collection5/last_62.txt  \n",
            "  inflating: Collection5/last_63.ann  \n",
            "  inflating: Collection5/last_63.txt  \n",
            "  inflating: Collection5/last_64.ann  \n",
            "  inflating: Collection5/last_64.txt  \n",
            "  inflating: Collection5/last_65.ann  \n",
            "  inflating: Collection5/last_65.txt  \n",
            "  inflating: Collection5/last_66.ann  \n",
            "  inflating: Collection5/last_66.txt  \n",
            "  inflating: Collection5/last_67.ann  \n",
            "  inflating: Collection5/last_67.txt  \n",
            "  inflating: Collection5/last_68.ann  \n",
            "  inflating: Collection5/last_68.txt  \n",
            "  inflating: Collection5/last_69.ann  \n",
            "  inflating: Collection5/last_69.txt  \n",
            "  inflating: Collection5/last_70.ann  \n",
            "  inflating: Collection5/last_70.txt  \n",
            "  inflating: Collection5/last_71.ann  \n",
            "  inflating: Collection5/last_71.txt  \n",
            "  inflating: Collection5/last_72.ann  \n",
            "  inflating: Collection5/last_72.txt  \n",
            "  inflating: Collection5/last_73.ann  \n",
            "  inflating: Collection5/last_73.txt  \n",
            "  inflating: Collection5/last_74.ann  \n",
            "  inflating: Collection5/last_74.txt  \n",
            "  inflating: Collection5/last_75.ann  \n",
            "  inflating: Collection5/last_75.txt  \n",
            "  inflating: Collection5/lenoblast.ann  \n",
            "  inflating: Collection5/lenoblast.txt  \n",
            "  inflating: Collection5/maykl dzhekson.ann  \n",
            "  inflating: Collection5/maykl dzhekson.txt  \n",
            "  inflating: Collection5/mvd.ann     \n",
            "  inflating: Collection5/mvd.txt     \n",
            "  inflating: Collection5/mvd2.ann    \n",
            "  inflating: Collection5/mvd2.txt    \n",
            "  inflating: Collection5/rosobrnadzor.ann  \n",
            "  inflating: Collection5/rosobrnadzor.txt  \n",
            "  inflating: Collection5/ryadovoy chelah.ann  \n",
            "  inflating: Collection5/ryadovoy chelah.txt  \n",
            "  inflating: Collection5/semenenko.ann  \n",
            "  inflating: Collection5/semenenko.txt  \n",
            "  inflating: Collection5/shojgu1.ann  \n",
            "  inflating: Collection5/shojgu1.txt  \n",
            "  inflating: Collection5/shojgu3.ann  \n",
            "  inflating: Collection5/shojgu3.txt  \n",
            "  inflating: Collection5/shojgu4.ann  \n",
            "  inflating: Collection5/shojgu4.txt  \n",
            "  inflating: Collection5/shojgu6.ann  \n",
            "  inflating: Collection5/shojgu6.txt  \n",
            "  inflating: Collection5/si_tzjanpin.ann  \n",
            "  inflating: Collection5/si_tzjanpin.txt  \n",
            "  inflating: Collection5/sobjanin2.ann  \n",
            "  inflating: Collection5/sobjanin2.txt  \n",
            "  inflating: Collection5/turkmenija.ann  \n",
            "  inflating: Collection5/turkmenija.txt  \n",
            "  inflating: Collection5/uchitel.ann  \n",
            "  inflating: Collection5/uchitel.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip collection5.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3fa065ee-fafc-42aa-8075-7a47bbe39615",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fa065ee-fafc-42aa-8075-7a47bbe39615",
        "outputId": "b17368e2-b7bf-40ee-a8a0-51e207f07968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object load_ne5 at 0x7f285200ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "records = load_ne5('./Collection5/')\n",
        "records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9ad28596-e268-42ac-b06d-08e6a322721a",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ad28596-e268-42ac-b06d-08e6a322721a",
        "outputId": "14913d7c-06b1-410d-bcb5-8f63b36b9b25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ne5Markup(\n",
              "    id='115',\n",
              "    text='Бывший глава ГУВД Москвы устроился на олимпийскую стройку в Сочи\\r\\n\\r\\nБывший глава ГУВД Москвы генерал-полковник Владимир Пронин перешел на работу в госкорпорацию \"Олимпстрой\". Об этом сообщает РИА Новости со ссылкой на заявление руководителя пресс-службы корпорации Александру Костерину. Она уточнила, что на работу в \"Олимпстрой\" Пронина пригласил президент госкорпорации Таймураз Боллоев.\\r\\n\\r\\nПо словам Костериной, Пронин начал работу в корпорации еще в конце июля 2010 года. \"Он занимается эксплуатацией олимпийских объектов, находящихся в ведении корпорации\", - сказала Костерина, добавив, что у Пронина имеется огромный опыт в сфере управления, поскольку он \"управлял такой \\'машиной\\', как московское ГУВД\".\\r\\n\\r\\nРаботает Пронин непосредственно в Сочи, где и находятся олимпийские объекты. Должность Пронина в пресс-службе не назвали.\\r\\n\\r\\nРанее сообщалось, что бывший глава ГУВД Москвы занимается преподавательской деятельностью.\\r\\n\\r\\nОб отставке Пронина стало известно в апреле 2009 года. Сообщалось, что начальник столичного ГУВД принял это решение после того, как майор милиции Денис Евсюков устроил стрельбу в супермаркете \"Остров\" на юге Москвы. Вместо Пронина руководителем столичного ГУВД был назначен генерал-майор милиции Владимир Колокольцев.\\r\\n\\r\\n\"Олимпстрой\", созданный в 2007 году, осуществляет управленческие функции, связанные с инженерными изысканиями при строительстве объектов, необходимых для проведения Олимпиады в Сочи. Кроме того, он занимается их проектированием, строительством, реконструкцией и организацией их эксплуатации. Всего к Олимпийским играм-2014 в Сочи планируется возвести несколько сотен различных объектов.\\r\\n\\r\\nЗимняя Олимпиада в Сочи станет самой дорогостоящей в истории: всего Россия потратит 950 миллиардов рублей на подготовку к Сочи-2014. ',\n",
              "    spans=[Ne5Span(\n",
              "         index='T1',\n",
              "         type='ORG',\n",
              "         start=13,\n",
              "         stop=17,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T2',\n",
              "         type='LOC',\n",
              "         start=18,\n",
              "         stop=24,\n",
              "         text='Москвы'\n",
              "     ), Ne5Span(\n",
              "         index='T3',\n",
              "         type='LOC',\n",
              "         start=60,\n",
              "         stop=64,\n",
              "         text='Сочи'\n",
              "     ), Ne5Span(\n",
              "         index='T4',\n",
              "         type='ORG',\n",
              "         start=81,\n",
              "         stop=85,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T5',\n",
              "         type='LOC',\n",
              "         start=86,\n",
              "         stop=92,\n",
              "         text='Москвы'\n",
              "     ), Ne5Span(\n",
              "         index='T6',\n",
              "         type='PER',\n",
              "         start=111,\n",
              "         stop=126,\n",
              "         text='Владимир Пронин'\n",
              "     ), Ne5Span(\n",
              "         index='T7',\n",
              "         type='ORG',\n",
              "         start=162,\n",
              "         stop=172,\n",
              "         text='Олимпстрой'\n",
              "     ), Ne5Span(\n",
              "         index='T8',\n",
              "         type='MEDIA',\n",
              "         start=192,\n",
              "         stop=203,\n",
              "         text='РИА Новости'\n",
              "     ), Ne5Span(\n",
              "         index='T9',\n",
              "         type='PER',\n",
              "         start=265,\n",
              "         stop=285,\n",
              "         text='Александру Костерину'\n",
              "     ), Ne5Span(\n",
              "         index='T10',\n",
              "         type='ORG',\n",
              "         start=318,\n",
              "         stop=328,\n",
              "         text='Олимпстрой'\n",
              "     ), Ne5Span(\n",
              "         index='T11',\n",
              "         type='PER',\n",
              "         start=330,\n",
              "         stop=337,\n",
              "         text='Пронина'\n",
              "     ), Ne5Span(\n",
              "         index='T12',\n",
              "         type='PER',\n",
              "         start=372,\n",
              "         stop=388,\n",
              "         text='Таймураз Боллоев'\n",
              "     ), Ne5Span(\n",
              "         index='T13',\n",
              "         type='PER',\n",
              "         start=403,\n",
              "         stop=413,\n",
              "         text='Костериной'\n",
              "     ), Ne5Span(\n",
              "         index='T14',\n",
              "         type='PER',\n",
              "         start=415,\n",
              "         stop=421,\n",
              "         text='Пронин'\n",
              "     ), Ne5Span(\n",
              "         index='T15',\n",
              "         type='PER',\n",
              "         start=572,\n",
              "         stop=581,\n",
              "         text='Костерина'\n",
              "     ), Ne5Span(\n",
              "         index='T16',\n",
              "         type='PER',\n",
              "         start=598,\n",
              "         stop=605,\n",
              "         text='Пронина'\n",
              "     ), Ne5Span(\n",
              "         index='T17',\n",
              "         type='ORG',\n",
              "         start=703,\n",
              "         stop=707,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T18',\n",
              "         type='PER',\n",
              "         start=722,\n",
              "         stop=728,\n",
              "         text='Пронин'\n",
              "     ), Ne5Span(\n",
              "         index='T19',\n",
              "         type='LOC',\n",
              "         start=747,\n",
              "         stop=751,\n",
              "         text='Сочи'\n",
              "     ), Ne5Span(\n",
              "         index='T20',\n",
              "         type='PER',\n",
              "         start=800,\n",
              "         stop=807,\n",
              "         text='Пронина'\n",
              "     ), Ne5Span(\n",
              "         index='T21',\n",
              "         type='ORG',\n",
              "         start=873,\n",
              "         stop=877,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T22',\n",
              "         type='LOC',\n",
              "         start=878,\n",
              "         stop=884,\n",
              "         text='Москвы'\n",
              "     ), Ne5Span(\n",
              "         index='T23',\n",
              "         type='PER',\n",
              "         start=944,\n",
              "         stop=951,\n",
              "         text='Пронина'\n",
              "     ), Ne5Span(\n",
              "         index='T24',\n",
              "         type='ORG',\n",
              "         start=1024,\n",
              "         stop=1028,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T25',\n",
              "         type='PER',\n",
              "         start=1078,\n",
              "         stop=1091,\n",
              "         text='Денис Евсюков'\n",
              "     ), Ne5Span(\n",
              "         index='T26',\n",
              "         type='LOC',\n",
              "         start=1140,\n",
              "         stop=1146,\n",
              "         text='Москвы'\n",
              "     ), Ne5Span(\n",
              "         index='T27',\n",
              "         type='PER',\n",
              "         start=1155,\n",
              "         stop=1162,\n",
              "         text='Пронина'\n",
              "     ), Ne5Span(\n",
              "         index='T28',\n",
              "         type='ORG',\n",
              "         start=1188,\n",
              "         stop=1192,\n",
              "         text='ГУВД'\n",
              "     ), Ne5Span(\n",
              "         index='T29',\n",
              "         type='PER',\n",
              "         start=1228,\n",
              "         stop=1248,\n",
              "         text='Владимир Колокольцев'\n",
              "     ), Ne5Span(\n",
              "         index='T30',\n",
              "         type='ORG',\n",
              "         start=1254,\n",
              "         stop=1264,\n",
              "         text='Олимпстрой'\n",
              "     ), Ne5Span(\n",
              "         index='T31',\n",
              "         type='LOC',\n",
              "         start=1430,\n",
              "         stop=1434,\n",
              "         text='Сочи'\n",
              "     ), Ne5Span(\n",
              "         index='T32',\n",
              "         type='LOC',\n",
              "         start=1578,\n",
              "         stop=1582,\n",
              "         text='Сочи'\n",
              "     ), Ne5Span(\n",
              "         index='T33',\n",
              "         type='LOC',\n",
              "         start=1662,\n",
              "         stop=1666,\n",
              "         text='Сочи'\n",
              "     ), Ne5Span(\n",
              "         index='T34',\n",
              "         type='GEOPOLIT',\n",
              "         start=1711,\n",
              "         stop=1717,\n",
              "         text='Россия'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "next(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f9af5351-1293-4e19-8b1a-74e10c0c0fb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "f9af5351-1293-4e19-8b1a-74e10c0c0fb6",
        "outputId": "c3238283-15d5-41c9-c98c-3c8e7c76aa5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Суд в ЮАР обязал вернуть останки детей Манделы на место захоронения\\r\\n\\r\\n\\r\\nВ то время как Нельсон Мандела находится в больнице в критическом состоянии, разразился скандал о его последнем пристанище. Суд удовлетворил иск старшей дочери Манделы к его внуку о том, чтобы Мандела был похоронен в деревне Куну.\\r\\nВнук Нельсона Манделы Мандла Мандела\\r\\n\\r\\nСуд в ЮАР обязал внука экс-президента страны Мандлу Манделу вернуть останки троих детей Нельсона Манделы в деревню Куну, где тот вырос, сообщает в субботу агентство Рейтер.\\r\\n\\r\\nСкандал о последнем пристанище Манделы стал достоянием общественности в то время, как сам экс-президент находится в критическом состоянии в больнице Претории. Чтобы повысить престиж и туристическую привлекательность своей родной деревни Мвезо, его внук-депутат решил в 2005 году перезахоронить там останки детей экс-президента в надежде, что Манделу также похоронят в Мвезо. Помимо усыпальницы, он планирует создать в деревне отель и футбольный стадион.\\r\\n\\r\\nОднако старшая дочь Манделы Маказиве и другие 15 родственников выступили против этого, настаивая, чтобы первый темнокожий президент ЮАР был похоронен в их деревне — Куну. В четверг суд удовлетворил иск, однако уведомить Мандлу о решении суда должным образом не удалось. По информации Рейтер, шериф не смог попасть в дом внука Манделы и приколол решение суда к стене или к двери. Представитель Мандлы заявила агентству, что ее начальник никаких бумаг не получал.\\r\\n\\r\\nКак отмечает издание Independent, сам Мандела родился в Мвезо, но, как следует из оставленного им в 1997 году завещания, выразил желание быть похороненным рядом с родными в Куну, где прошло его детство. Рядом с могилой экс-президент ЮАР завещал разбить сад в его память.\\r\\n\\r\\nВ начале июня Мандела попал в госпиталь в Претории с рецидивом легочной инфекции. Несколько дней назад его состояние стало критическим, хотя затем значительно улучшилось. Известный борец против режима апартеида, он провел в тюрьме 27 лет. В мае 1994 года Мандела стал первым чернокожим президентом ЮАР и руководил государством до июня 1999 года. В 1993 году был награжден Нобелевской премией мира.\\r\\n\\r\\nЧем известен Нельсон Мандела\\r\\n\\r\\nНельсон Мандела стал первым в истории чернокожим президентом ЮАР. Он руководил государством с мая 1994 по июнь 1999 года. За свою активную деятельность против режима апартеида он провел в тюрьме 27 лет. В 1993 году Мандела был награжден Нобелевской премией мира. \\r\\n\\r\\nКак у экс-президента ЮАР обострились проблемы со здоровьем\\r\\n\\r\\nВ начале декабря 2012 года Мандела был госпитализирован в Йоханнесбурге. Врачи провели ряд тестов, которые выявили рецидив легочной инфекции, потребовавший соответствующего лечения. Позже экс-президенту ЮАР была успешно проведена операция по удалению камней из желчного пузыря. Незадолго до наступления нового года он был выписан из больницы.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "doc = next(records).text\n",
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "adf54d80-f2f5-4754-9cf9-da12c77ca968",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adf54d80-f2f5-4754-9cf9-da12c77ca968",
        "outputId": "fa1f54a8-840b-4d7d-afd8-985e35593fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ab7be373-a7d4-4e8d-b2ab-06c25d9192f2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7be373-a7d4-4e8d-b2ab-06c25d9192f2",
        "outputId": "3c97c520-fa6e-44f9-a87a-d40042a7ece8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Суд', 'JJ'),\n",
              " ('в', 'NNP'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('обязал', 'NNP'),\n",
              " ('вернуть', 'NNP'),\n",
              " ('останки', 'NNP'),\n",
              " ('детей', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('на', 'NNP'),\n",
              " ('место', 'NNP'),\n",
              " ('захоронения', 'NNP'),\n",
              " ('В', 'NNP'),\n",
              " ('то', 'NNP'),\n",
              " ('время', 'NNP'),\n",
              " ('как', 'NNP'),\n",
              " ('Нельсон', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('находится', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('больнице', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('критическом', 'NNP'),\n",
              " ('состоянии', 'NNP'),\n",
              " (',', ','),\n",
              " ('разразился', 'NNP'),\n",
              " ('скандал', 'NNP'),\n",
              " ('о', 'NNP'),\n",
              " ('его', 'NNP'),\n",
              " ('последнем', 'NNP'),\n",
              " ('пристанище', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Суд', 'VB'),\n",
              " ('удовлетворил', 'JJ'),\n",
              " ('иск', 'NNP'),\n",
              " ('старшей', 'NNP'),\n",
              " ('дочери', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('к', 'NNP'),\n",
              " ('его', 'NNP'),\n",
              " ('внуку', 'NNP'),\n",
              " ('о', 'NNP'),\n",
              " ('том', 'NNP'),\n",
              " (',', ','),\n",
              " ('чтобы', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('похоронен', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('деревне', 'NNP'),\n",
              " ('Куну', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Внук', 'VB'),\n",
              " ('Нельсона', 'JJ'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('Мандла', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('Суд', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('обязал', 'NNP'),\n",
              " ('внука', 'NNP'),\n",
              " ('экс-президента', 'JJ'),\n",
              " ('страны', 'NNP'),\n",
              " ('Мандлу', 'NNP'),\n",
              " ('Манделу', 'NNP'),\n",
              " ('вернуть', 'NNP'),\n",
              " ('останки', 'NNP'),\n",
              " ('троих', 'NNP'),\n",
              " ('детей', 'NNP'),\n",
              " ('Нельсона', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('деревню', 'NNP'),\n",
              " ('Куну', 'NNP'),\n",
              " (',', ','),\n",
              " ('где', 'NNP'),\n",
              " ('тот', 'NNP'),\n",
              " ('вырос', 'NNP'),\n",
              " (',', ','),\n",
              " ('сообщает', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('субботу', 'NNP'),\n",
              " ('агентство', 'NNP'),\n",
              " ('Рейтер', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Скандал', 'VB'),\n",
              " ('о', 'JJ'),\n",
              " ('последнем', 'NNP'),\n",
              " ('пристанище', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('стал', 'NNP'),\n",
              " ('достоянием', 'NNP'),\n",
              " ('общественности', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('то', 'NNP'),\n",
              " ('время', 'NNP'),\n",
              " (',', ','),\n",
              " ('как', 'NNP'),\n",
              " ('сам', 'NNP'),\n",
              " ('экс-президент', 'JJ'),\n",
              " ('находится', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('критическом', 'NNP'),\n",
              " ('состоянии', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('больнице', 'NNP'),\n",
              " ('Претории', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Чтобы', 'VB'),\n",
              " ('повысить', 'JJ'),\n",
              " ('престиж', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('туристическую', 'NNP'),\n",
              " ('привлекательность', 'NNP'),\n",
              " ('своей', 'NNP'),\n",
              " ('родной', 'NNP'),\n",
              " ('деревни', 'NNP'),\n",
              " ('Мвезо', 'NNP'),\n",
              " (',', ','),\n",
              " ('его', 'NNP'),\n",
              " ('внук-депутат', 'NNP'),\n",
              " ('решил', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('2005', 'CD'),\n",
              " ('году', 'NNP'),\n",
              " ('перезахоронить', 'NNP'),\n",
              " ('там', 'NNP'),\n",
              " ('останки', 'NNP'),\n",
              " ('детей', 'NNP'),\n",
              " ('экс-президента', 'JJ'),\n",
              " ('в', 'NNP'),\n",
              " ('надежде', 'NNP'),\n",
              " (',', ','),\n",
              " ('что', 'NNP'),\n",
              " ('Манделу', 'NNP'),\n",
              " ('также', 'NNP'),\n",
              " ('похоронят', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Мвезо', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Помимо', 'NN'),\n",
              " ('усыпальницы', 'NN'),\n",
              " (',', ','),\n",
              " ('он', 'NNP'),\n",
              " ('планирует', 'NNP'),\n",
              " ('создать', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('деревне', 'NNP'),\n",
              " ('отель', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('футбольный', 'NNP'),\n",
              " ('стадион', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Однако', 'VB'),\n",
              " ('старшая', 'JJ'),\n",
              " ('дочь', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('Маказиве', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('другие', 'VBD'),\n",
              " ('15', 'CD'),\n",
              " ('родственников', 'NNP'),\n",
              " ('выступили', 'NNP'),\n",
              " ('против', 'NNP'),\n",
              " ('этого', 'NNP'),\n",
              " (',', ','),\n",
              " ('настаивая', 'NNP'),\n",
              " (',', ','),\n",
              " ('чтобы', 'NNP'),\n",
              " ('первый', 'NNP'),\n",
              " ('темнокожий', 'NNP'),\n",
              " ('президент', 'NNP'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('похоронен', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('их', 'NNP'),\n",
              " ('деревне', 'NNP'),\n",
              " ('—', 'NNP'),\n",
              " ('Куну', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('В', 'VB'),\n",
              " ('четверг', 'JJ'),\n",
              " ('суд', 'NNP'),\n",
              " ('удовлетворил', 'NNP'),\n",
              " ('иск', 'NNP'),\n",
              " (',', ','),\n",
              " ('однако', 'NNP'),\n",
              " ('уведомить', 'NNP'),\n",
              " ('Мандлу', 'NNP'),\n",
              " ('о', 'NNP'),\n",
              " ('решении', 'NNP'),\n",
              " ('суда', 'NNP'),\n",
              " ('должным', 'NNP'),\n",
              " ('образом', 'NNP'),\n",
              " ('не', 'NNP'),\n",
              " ('удалось', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('По', 'VB'),\n",
              " ('информации', 'JJ'),\n",
              " ('Рейтер', 'NNP'),\n",
              " (',', ','),\n",
              " ('шериф', 'NNP'),\n",
              " ('не', 'NNP'),\n",
              " ('смог', 'NNP'),\n",
              " ('попасть', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('дом', 'NNP'),\n",
              " ('внука', 'NNP'),\n",
              " ('Манделы', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('приколол', 'NNP'),\n",
              " ('решение', 'NNP'),\n",
              " ('суда', 'NNP'),\n",
              " ('к', 'NNP'),\n",
              " ('стене', 'NNP'),\n",
              " ('или', 'NNP'),\n",
              " ('к', 'NNP'),\n",
              " ('двери', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Представитель', 'VB'),\n",
              " ('Мандлы', 'JJ'),\n",
              " ('заявила', 'NNP'),\n",
              " ('агентству', 'NNP'),\n",
              " (',', ','),\n",
              " ('что', 'NNP'),\n",
              " ('ее', 'NNP'),\n",
              " ('начальник', 'NNP'),\n",
              " ('никаких', 'NNP'),\n",
              " ('бумаг', 'NNP'),\n",
              " ('не', 'NNP'),\n",
              " ('получал', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Как', 'VB'),\n",
              " ('отмечает', 'JJ'),\n",
              " ('издание', 'NNP'),\n",
              " ('Independent', 'NNP'),\n",
              " (',', ','),\n",
              " ('сам', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('родился', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Мвезо', 'NNP'),\n",
              " (',', ','),\n",
              " ('но', 'NNP'),\n",
              " (',', ','),\n",
              " ('как', 'NNP'),\n",
              " ('следует', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('оставленного', 'NNP'),\n",
              " ('им', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('1997', 'CD'),\n",
              " ('году', 'NNP'),\n",
              " ('завещания', 'NNP'),\n",
              " (',', ','),\n",
              " ('выразил', 'NNP'),\n",
              " ('желание', 'NNP'),\n",
              " ('быть', 'NNP'),\n",
              " ('похороненным', 'NNP'),\n",
              " ('рядом', 'NNP'),\n",
              " ('с', 'NNP'),\n",
              " ('родными', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Куну', 'NNP'),\n",
              " (',', ','),\n",
              " ('где', 'NNP'),\n",
              " ('прошло', 'NNP'),\n",
              " ('его', 'NNP'),\n",
              " ('детство', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Рядом', 'VB'),\n",
              " ('с', 'JJ'),\n",
              " ('могилой', 'NNP'),\n",
              " ('экс-президент', 'JJ'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('завещал', 'NNP'),\n",
              " ('разбить', 'NNP'),\n",
              " ('сад', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('его', 'NNP'),\n",
              " ('память', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('В', 'VB'),\n",
              " ('начале', 'JJ'),\n",
              " ('июня', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('попал', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('госпиталь', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Претории', 'NNP'),\n",
              " ('с', 'NNP'),\n",
              " ('рецидивом', 'NNP'),\n",
              " ('легочной', 'NNP'),\n",
              " ('инфекции', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Несколько', 'VB'),\n",
              " ('дней', 'JJ'),\n",
              " ('назад', 'NNP'),\n",
              " ('его', 'NNP'),\n",
              " ('состояние', 'NNP'),\n",
              " ('стало', 'NNP'),\n",
              " ('критическим', 'NNP'),\n",
              " (',', ','),\n",
              " ('хотя', 'NNP'),\n",
              " ('затем', 'NNP'),\n",
              " ('значительно', 'NNP'),\n",
              " ('улучшилось', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Известный', 'VB'),\n",
              " ('борец', 'JJ'),\n",
              " ('против', 'NNP'),\n",
              " ('режима', 'NNP'),\n",
              " ('апартеида', 'NNP'),\n",
              " (',', ','),\n",
              " ('он', 'NNP'),\n",
              " ('провел', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('тюрьме', 'VBD'),\n",
              " ('27', 'CD'),\n",
              " ('лет', 'NN'),\n",
              " ('.', '.'),\n",
              " ('В', 'CC'),\n",
              " ('мае', 'JJ'),\n",
              " ('1994', 'CD'),\n",
              " ('года', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('стал', 'NNP'),\n",
              " ('первым', 'NNP'),\n",
              " ('чернокожим', 'NNP'),\n",
              " ('президентом', 'NNP'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('и', 'NNP'),\n",
              " ('руководил', 'NNP'),\n",
              " ('государством', 'NNP'),\n",
              " ('до', 'NNP'),\n",
              " ('июня', 'NNP'),\n",
              " ('1999', 'CD'),\n",
              " ('года', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('В', 'NN'),\n",
              " ('1993', 'CD'),\n",
              " ('году', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('награжден', 'NNP'),\n",
              " ('Нобелевской', 'NNP'),\n",
              " ('премией', 'NNP'),\n",
              " ('мира', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Чем', 'VB'),\n",
              " ('известен', 'JJ'),\n",
              " ('Нельсон', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('Нельсон', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('стал', 'NNP'),\n",
              " ('первым', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('истории', 'NNP'),\n",
              " ('чернокожим', 'NNP'),\n",
              " ('президентом', 'NNP'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Он', 'VB'),\n",
              " ('руководил', 'JJ'),\n",
              " ('государством', 'NNP'),\n",
              " ('с', 'NNP'),\n",
              " ('мая', 'NNP'),\n",
              " ('1994', 'CD'),\n",
              " ('по', 'NNP'),\n",
              " ('июнь', 'NN'),\n",
              " ('1999', 'CD'),\n",
              " ('года', 'NN'),\n",
              " ('.', '.'),\n",
              " ('За', 'CC'),\n",
              " ('свою', 'JJ'),\n",
              " ('активную', 'NNP'),\n",
              " ('деятельность', 'NNP'),\n",
              " ('против', 'NNP'),\n",
              " ('режима', 'NNP'),\n",
              " ('апартеида', 'NNP'),\n",
              " ('он', 'NNP'),\n",
              " ('провел', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('тюрьме', 'VBD'),\n",
              " ('27', 'CD'),\n",
              " ('лет', 'NN'),\n",
              " ('.', '.'),\n",
              " ('В', 'JJ'),\n",
              " ('1993', 'CD'),\n",
              " ('году', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('награжден', 'NNP'),\n",
              " ('Нобелевской', 'NNP'),\n",
              " ('премией', 'NNP'),\n",
              " ('мира', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Как', 'VB'),\n",
              " ('у', 'JJ'),\n",
              " ('экс-президента', 'JJ'),\n",
              " ('ЮАР', 'NN'),\n",
              " ('обострились', 'NNP'),\n",
              " ('проблемы', 'NNP'),\n",
              " ('со', 'NNP'),\n",
              " ('здоровьем', 'NNP'),\n",
              " ('В', 'NNP'),\n",
              " ('начале', 'NNP'),\n",
              " ('декабря', 'NNP'),\n",
              " ('2012', 'CD'),\n",
              " ('года', 'NNP'),\n",
              " ('Мандела', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('госпитализирован', 'NNP'),\n",
              " ('в', 'NNP'),\n",
              " ('Йоханнесбурге', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Врачи', 'VB'),\n",
              " ('провели', 'JJ'),\n",
              " ('ряд', 'NNP'),\n",
              " ('тестов', 'NNP'),\n",
              " (',', ','),\n",
              " ('которые', 'NNP'),\n",
              " ('выявили', 'NNP'),\n",
              " ('рецидив', 'NNP'),\n",
              " ('легочной', 'NNP'),\n",
              " ('инфекции', 'NNP'),\n",
              " (',', ','),\n",
              " ('потребовавший', 'NNP'),\n",
              " ('соответствующего', 'NNP'),\n",
              " ('лечения', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Позже', 'VB'),\n",
              " ('экс-президенту', 'JJ'),\n",
              " ('ЮАР', 'NNP'),\n",
              " ('была', 'NNP'),\n",
              " ('успешно', 'NNP'),\n",
              " ('проведена', 'NNP'),\n",
              " ('операция', 'NNP'),\n",
              " ('по', 'NNP'),\n",
              " ('удалению', 'NNP'),\n",
              " ('камней', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('желчного', 'NNP'),\n",
              " ('пузыря', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Незадолго', 'VB'),\n",
              " ('до', 'JJ'),\n",
              " ('наступления', 'NNP'),\n",
              " ('нового', 'NNP'),\n",
              " ('года', 'NNP'),\n",
              " ('он', 'NNP'),\n",
              " ('был', 'NNP'),\n",
              " ('выписан', 'NNP'),\n",
              " ('из', 'NNP'),\n",
              " ('больницы', 'NNP'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6fc0c750-a22b-4afb-aaa6-b35f648d169c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fc0c750-a22b-4afb-aaa6-b35f648d169c",
        "outputId": "ea952cc2-b65f-446b-c17b-386f288bb1ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('Мандела', 'PERSON'),\n",
              " ('Манделу', 'PERSON'),\n",
              " ('Манделы', 'PERSON'),\n",
              " ('Манделы Маказиве', 'PERSON'),\n",
              " ('Мандлу', 'PERSON'),\n",
              " ('Мандлу Манделу', 'PERSON'),\n",
              " ('Мандлы', 'PERSON'),\n",
              " ('Нельсон Мандела', 'PERSON'),\n",
              " ('Нельсон Мандела Нельсон Мандела', 'PERSON'),\n",
              " ('Нельсона Манделы Мандла Мандела Суд', 'PERSON'),\n",
              " ('Помимо', 'PERSON'),\n",
              " ('Рейтер', 'GPE'),\n",
              " ('ЮАР', 'ORGANIZATION')}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(doc))) if hasattr(chunk, 'label') }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee240614-0f75-44dd-894a-d6c51f141a1d",
      "metadata": {
        "id": "ee240614-0f75-44dd-894a-d6c51f141a1d"
      },
      "source": [
        "Ошибки есть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7a314c65-98d0-4e9b-a868-a0b3a8424c95",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7a314c65-98d0-4e9b-a868-a0b3a8424c95",
        "outputId": "a02bbf62-612e-49b5-e359-2c624733ceb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deeppavlov\n",
            "  Downloading deeppavlov-0.17.4-py3-none-any.whl (878 kB)\n",
            "\u001b[K     |████████████████████████████████| 878 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 20.2 MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting prometheus-client==0.7.1\n",
            "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
            "Collecting pytelegrambotapi==3.6.7\n",
            "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.17.3)\n",
            "Collecting overrides==2.7.0\n",
            "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
            "Collecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 44.4 MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 8.5 MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 44.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 2.4 MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
            "Collecting pydantic==1.3\n",
            "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 23.1 MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 920 bytes/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 11.3 MB/s \n",
            "\u001b[?25hCollecting pyopenssl==22.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.7 MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 25.8 MB/s \n",
            "\u001b[?25hCollecting cryptography>=35.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Collecting websockets==8.*\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*\n",
            "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 74.6 MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
            "Collecting multidict>=4.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.1.1)\n",
            "Building wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449924 sha256=88e9ad4e9f2cb74096da90805fd13a4e20c1263f051941e8ba1e07e4096b7746\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5603 sha256=2fc68519326c9ba0b4053ef85ec22bad1f14dc8f251493d4569c4d84f97d2b1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41405 sha256=3d75be5574bda745eaa1970b5ace6c97d403f84ac0bece08674e8103532a0248\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=3ea11618e36f1c14d04619755b9a665af2ae8d56efc91d6d22a04776de764dce\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=eeed173915a4bdfbc16cceed9a78462978387d7f534e372b327ec19891121752\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=fed883e7170ebe385a2f50ed56c441ab04921f667c3329a41036bd29739507f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
            "Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, tqdm, starlette, scipy, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.1\n",
            "    Uninstalling pytz-2022.1:\n",
            "      Successfully uninstalled pytz-2022.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.8.2\n",
            "    Uninstalling pydantic-1.8.2:\n",
            "      Successfully uninstalled pydantic-1.8.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.14.1\n",
            "    Uninstalling prometheus-client-0.14.1:\n",
            "      Successfully uninstalled prometheus-client-0.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.7.1\n",
            "    Uninstalling filelock-3.7.1:\n",
            "      Successfully uninstalled filelock-3.7.1\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.30\n",
            "    Uninstalling Cython-0.29.30:\n",
            "      Successfully uninstalled Cython-0.29.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "spacy 3.3.1 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.4.1 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.14+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.14 requires numpy>=1.19, but you have numpy 1.18.0 which is incompatible.\n",
            "jax 0.3.14 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-37.0.4 dawg-python-0.7.2 deeppavlov-0.17.4 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-6.0.2 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-22.0.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 scipy-1.4.1 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "numpy",
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-17 18:07:28.260 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-hzsvfrfq\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-hzsvfrfq\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23593 sha256=9db1bb6317b2e4471ee8ce69b7e4e4a2eb809a4f8fd233143bcfb47e2c907dd8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-814pxjxz/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.47.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=4e838243fea5dbd6a0bb1e425d987659f31897552d3e10fc077a077b431b3a9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n",
            "2022-07-17 18:08:10.785 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==1.15.5 in /usr/local/lib/python3.7/dist-packages (1.15.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.47.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.8.1\n",
            "  Downloading gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 83.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.18.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_bert\n",
        "!python -m deeppavlov install ner_ontonotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "bf6dafb2-3210-443c-a799-e3ddeefe625b",
      "metadata": {
        "id": "bf6dafb2-3210-443c-a799-e3ddeefe625b"
      },
      "outputs": [],
      "source": [
        "import deeppavlov\n",
        "from deeppavlov import configs, build_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5e480aca-ed0f-4ff2-9de6-87b97510d12b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5e480aca-ed0f-4ff2-9de6-87b97510d12b",
        "outputId": "953c62da-46bd-4608-f063-748fa0ee4921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-17 18:08:21.814 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz to /root/.deeppavlov/models/ner_cq_rus.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [01:17<00:00, 17.0MB/s]\n",
            "2022-07-17 18:09:40.290 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/ner_cq_rus.tar.gz archive into /root/.deeppavlov/models/ner_ent_and_type_rus\n",
            "2022-07-17 18:09:53.923 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n",
            "100%|██████████| 663M/663M [00:41<00:00, 16.0MB/s]\n",
            "2022-07-17 18:10:36.227 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n",
            "2022-07-17 18:10:43.115 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle to /root/.deeppavlov/models/entity_and_type_detection_rus.pickle\n",
            "100%|██████████| 2.07M/2.07M [00:00<00:00, 2.72MB/s]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-17 18:10:47.60 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-17 18:10:47.814 ERROR in 'deeppavlov.core.common.params'['params'] at line 112: Exception in <class 'deeppavlov.models.bert.bert_sequence_tagger.BertSequenceTagger'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/params.py\", line 106, in from_params\n",
            "    component = obj(**dict(config_params, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 76, in __call__\n",
            "    obj.__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\", line 529, in __init__\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\", line 240, in __init__\n",
            "    self._init_graph()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\", line 534, in _init_graph\n",
            "    units = super()._init_graph()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\", line 272, in _init_graph\n",
            "    use_one_hot_embeddings=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py\", line 208, in __init__\n",
            "    input_ids, input_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py\", line 559, in create_attention_mask_from_input_mask\n",
            "    shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2560, in ones\n",
            "    output = _constant_if_small(one, shape, dtype, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2295, in _constant_if_small\n",
            "    if np.prod(shape) < 1000:\n",
            "  File \"<__array_function__ internals>\", line 6, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 3052, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
            "    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 736, in __array__\n",
            "    \" array.\".format(self.name))\n",
            "NotImplementedError: Cannot convert a symbolic Tensor (bert/encoder/strided_slice:0) to a numpy array.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-3a5530cc7b27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeppavlov_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner_bert_ent_and_type_rus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdeeppavlov_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, download, serialized)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcomponent_serialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_serialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(params, mode, serialized, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0m_refs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mwrapped_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_tags, keep_prob, bert_config_file, pretrained_bert, attention_probs_keep_prob, hidden_keep_prob, use_crf, encoder_layer_ids, encoder_dropout, optimizer, weight_decay_rate, use_birnn, birnn_cell_type, birnn_hidden_size, ema_decay, ema_variables_on_cpu, return_probas, freeze_embeddings, learning_rate, bert_learning_rate, min_learning_rate, learning_rate_drop_patience, learning_rate_drop_div, load_before_drop, clip_norm, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m                          \u001b[0mload_before_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_before_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                          \u001b[0mclip_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, keep_prob, bert_config_file, pretrained_bert, attention_probs_keep_prob, hidden_keep_prob, encoder_layer_ids, encoder_dropout, optimizer, weight_decay_rate, ema_decay, ema_variables_on_cpu, freeze_embeddings, learning_rate, bert_learning_rate, min_learning_rate, learning_rate_drop_patience, learning_rate_drop_div, load_before_drop, clip_norm, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\u001b[0m in \u001b[0;36m_init_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py\u001b[0m in \u001b[0;36m_init_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                               \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_masks_ph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                               \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_types_ph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                               use_one_hot_embeddings=False)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, is_training, input_ids, input_mask, token_type_ids, use_one_hot_embeddings, scope)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# for the attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         attention_mask = create_attention_mask_from_input_mask(\n\u001b[0;32m--> 208\u001b[0;31m             input_ids, input_mask)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;31m# Run the stacked transformer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py\u001b[0m in \u001b[0;36mcreate_attention_mask_from_input_mask\u001b[0;34m(from_tensor, to_mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[0;31m# `broadcast_ones` = [batch_size, from_seq_length, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m   broadcast_ones = tf.ones(\n\u001b[0;32m--> 559\u001b[0;31m       shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m   \u001b[0;31m# Here we broadcast along two dimensions to create the mask.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2558\u001b[0m         \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m         \u001b[0;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2296\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \u001b[0mnumber_of_dimensions\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mScalars\u001b[0m \u001b[0mare\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3052\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# support a dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[0;32m--> 736\u001b[0;31m                               \" array.\".format(self.name))\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (bert/encoder/strided_slice:0) to a numpy array."
          ]
        }
      ],
      "source": [
        "deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)\n",
        "deeppavlov_ner([doc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "9e3a0581-33ad-4335-8fa2-13ebccacc50e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e3a0581-33ad-4335-8fa2-13ebccacc50e",
        "outputId": "0b283c14-237e-453b-a48f-bb290f11a843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.22.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.3\n",
            "    Uninstalling pydantic-1.3:\n",
            "      Successfully uninstalled pydantic-1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "deeppavlov 0.17.4 requires pydantic==1.3, but you have pydantic 1.8.2 which is incompatible.\u001b[0m\n",
            "Successfully installed pydantic-1.8.2\n"
          ]
        }
      ],
      "source": [
        "#!pip install wrapt\n",
        "!pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozuLe26eTVOp",
        "outputId": "7227ec9e-1aee-46ea-8ba6-2ab8caab069f"
      },
      "id": "ozuLe26eTVOp",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ru-core-news-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.3.0/ru_core_news_sm-3.3.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-sm==3.3.0) (3.3.1)\n",
            "Collecting pymorphy2>=0.9\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.3.0) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-sm==3.3.0) (0.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.18.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.22.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (4.62.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.7.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->ru-core-news-sm==3.3.0) (2.0.1)\n",
            "Installing collected packages: pymorphy2, ru-core-news-sm\n",
            "  Attempting uninstall: pymorphy2\n",
            "    Found existing installation: pymorphy2 0.8\n",
            "    Uninstalling pymorphy2-0.8:\n",
            "      Successfully uninstalled pymorphy2-0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "deeppavlov 0.17.4 requires pydantic==1.3, but you have pydantic 1.8.2 which is incompatible.\n",
            "deeppavlov 0.17.4 requires pymorphy2==0.8, but you have pymorphy2 0.9.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pymorphy2-0.9.1 ru-core-news-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "a2dd4ed4-9c73-4874-b016-dbd560d8783c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a2dd4ed4-9c73-4874-b016-dbd560d8783c",
        "outputId": "02246877-72de-4bde-f66f-c741aaaceddf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Суд в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " обязал вернуть останки детей \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " на место захоронения\r</br>\r</br>\r</br>В то время как \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Нельсон Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " находится в больнице в критическом состоянии, разразился скандал о его последнем пристанище. Суд удовлетворил иск старшей дочери \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " к его внуку о том, чтобы \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " был похоронен в деревне \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Куну\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".\r</br>Внук Нельсона \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы Мандла Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              "\r</br>\r</br>Суд в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " обязал внука экс-президента страны \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандлу Манделу\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " вернуть останки троих детей \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Нельсона Манделы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " в деревню \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Куну\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", где тот вырос, сообщает в субботу агентство \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Рейтер\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".\r</br>\r</br>Скандал о последнем пристанище \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " стал достоянием общественности в то время, как сам экс-президент находится в критическом состоянии в больнице \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Претории\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". Чтобы повысить престиж и туристическую привлекательность своей родной деревни \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мвезо\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", его внук-депутат решил в 2005 году перезахоронить там останки детей экс-президента в надежде, что \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделу\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " также похоронят в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мвезо\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". Помимо усыпальницы, он планирует создать в деревне отель и футбольный стадион.\r</br>\r</br>Однако старшая дочь \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы Маказиве\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " и другие 15 родственников выступили против этого, настаивая, чтобы первый темнокожий президент \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " был похоронен в их деревне — \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Куну\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". В четверг суд удовлетворил иск, однако уведомить \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандлу\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " о решении суда должным образом не удалось. По информации \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Рейтер\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", шериф не смог попасть в дом внука \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Манделы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " и приколол решение суда к стене или к двери. Представитель \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандлы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " заявила агентству, что ее начальник никаких бумаг не получал.\r</br>\r</br>Как отмечает издание \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Independent\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", сам \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " родился в \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мвезо\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              ", но, как следует из оставленного им в 1997 году завещания, выразил желание быть похороненным рядом с родными в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Куну\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", где прошло его детство. Рядом с могилой экс-президент \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " завещал разбить сад в его память.\r</br>\r</br>В начале июня \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " попал в госпиталь в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Претории\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " с рецидивом легочной инфекции. Несколько дней назад его состояние стало критическим, хотя затем значительно улучшилось. Известный борец против режима апартеида, он провел в тюрьме 27 лет. В мае 1994 года \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " стал первым чернокожим президентом \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " и руководил государством до июня 1999 года. В 1993 году был награжден Нобелевской премией мира.\r</br>\r</br>Чем известен \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Нельсон Мандела\r\n",
              "\r\n",
              "\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              "\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Нельсон Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " стал первым в истории чернокожим президентом \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". Он руководил государством с мая 1994 по июнь 1999 года. За свою активную деятельность против режима апартеида он провел в тюрьме 27 лет. В 1993 году \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " был награжден Нобелевской премией мира. \r</br>\r</br>Как у экс-президента \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " обострились проблемы со здоровьем\r</br>\r</br>В начале декабря 2012 года \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Мандела\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
              "</mark>\n",
              " был госпитализирован в \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Йоханнесбурге\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ". Врачи провели ряд тестов, которые выявили рецидив легочной инфекции, потребовавший соответствующего лечения. Позже экс-президенту \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ЮАР\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " была успешно проведена операция по удалению камней из желчного пузыря. Незадолго до наступления нового года он был выписан из больницы.</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "article = nlp(doc)\n",
        "displacy.render(article, jupyter=True, style='ent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "cbdf558d-bcdf-4437-a628-3f1239c331ad",
      "metadata": {
        "id": "cbdf558d-bcdf-4437-a628-3f1239c331ad"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bed8e8ef-da98-4547-86db-21fc10c1f27c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bed8e8ef-da98-4547-86db-21fc10c1f27c",
        "outputId": "9cd33824-5321-443d-9ffe-b0f97dd2fcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize"
      ],
      "metadata": {
        "id": "tG8-AOCAUIVY"
      },
      "id": "tG8-AOCAUIVY",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ],
      "metadata": {
        "id": "hlmUIonQUK9B"
      },
      "id": "hlmUIonQUK9B",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yqO_yPNdUWr_"
      },
      "id": "yqO_yPNdUWr_",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvEFzXp6UZWQ",
        "outputId": "7d997151-6fd7-4d00-b453-dc24f4d5b689"
      },
      "id": "LvEFzXp6UZWQ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Бывший', 'OUT'],\n",
              " ['глава', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['Москвы', 'LOC'],\n",
              " ['устроился', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['олимпийскую', 'OUT'],\n",
              " ['стройку', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Сочи', 'LOC'],\n",
              " ['Бывший', 'OUT'],\n",
              " ['глава', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['Москвы', 'LOC'],\n",
              " ['генерал-полковник', 'OUT'],\n",
              " ['Владимир', 'PER'],\n",
              " ['Пронин', 'PER'],\n",
              " ['перешел', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['работу', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['госкорпорацию', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Олимпстрой', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Об', 'OUT'],\n",
              " ['этом', 'OUT'],\n",
              " ['сообщает', 'OUT'],\n",
              " ['РИА', 'MEDIA'],\n",
              " ['Новости', 'MEDIA'],\n",
              " ['со', 'OUT'],\n",
              " ['ссылкой', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['заявление', 'OUT'],\n",
              " ['руководителя', 'OUT'],\n",
              " ['пресс-службы', 'OUT'],\n",
              " ['корпорации', 'OUT'],\n",
              " ['Александру', 'PER'],\n",
              " ['Костерину', 'PER'],\n",
              " ['.', 'OUT'],\n",
              " ['Она', 'OUT'],\n",
              " ['уточнила', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['работу', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Олимпстрой', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " ['Пронина', 'PER'],\n",
              " ['пригласил', 'OUT'],\n",
              " ['президент', 'OUT'],\n",
              " ['госкорпорации', 'OUT'],\n",
              " ['Таймураз', 'PER'],\n",
              " ['Боллоев', 'PER'],\n",
              " ['.', 'OUT'],\n",
              " ['По', 'OUT'],\n",
              " ['словам', 'OUT'],\n",
              " ['Костериной', 'PER'],\n",
              " [',', 'OUT'],\n",
              " ['Пронин', 'PER'],\n",
              " ['начал', 'OUT'],\n",
              " ['работу', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['корпорации', 'OUT'],\n",
              " ['еще', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['конце', 'OUT'],\n",
              " ['июля', 'OUT'],\n",
              " ['2010', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Он', 'OUT'],\n",
              " ['занимается', 'OUT'],\n",
              " ['эксплуатацией', 'OUT'],\n",
              " ['олимпийских', 'OUT'],\n",
              " ['объектов', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['находящихся', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['ведении', 'OUT'],\n",
              " ['корпорации', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['-', 'OUT'],\n",
              " ['сказала', 'OUT'],\n",
              " ['Костерина', 'PER'],\n",
              " [',', 'OUT'],\n",
              " ['добавив', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['у', 'OUT'],\n",
              " ['Пронина', 'PER'],\n",
              " ['имеется', 'OUT'],\n",
              " ['огромный', 'OUT'],\n",
              " ['опыт', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['сфере', 'OUT'],\n",
              " ['управления', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['поскольку', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['управлял', 'OUT'],\n",
              " ['такой', 'OUT'],\n",
              " [\"'\", 'OUT'],\n",
              " ['машиной', 'OUT'],\n",
              " [\"'\", 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['московское', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Работает', 'OUT'],\n",
              " ['Пронин', 'PER'],\n",
              " ['непосредственно', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Сочи', 'LOC'],\n",
              " [',', 'OUT'],\n",
              " ['где', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['находятся', 'OUT'],\n",
              " ['олимпийские', 'OUT'],\n",
              " ['объекты', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Должность', 'OUT'],\n",
              " ['Пронина', 'PER'],\n",
              " ['в', 'OUT'],\n",
              " ['пресс-службе', 'OUT'],\n",
              " ['не', 'OUT'],\n",
              " ['назвали', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Ранее', 'OUT'],\n",
              " ['сообщалось', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['бывший', 'OUT'],\n",
              " ['глава', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['Москвы', 'LOC'],\n",
              " ['занимается', 'OUT'],\n",
              " ['преподавательской', 'OUT'],\n",
              " ['деятельностью', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Об', 'OUT'],\n",
              " ['отставке', 'OUT'],\n",
              " ['Пронина', 'PER'],\n",
              " ['стало', 'OUT'],\n",
              " ['известно', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['апреле', 'OUT'],\n",
              " ['2009', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Сообщалось', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['начальник', 'OUT'],\n",
              " ['столичного', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['принял', 'OUT'],\n",
              " ['это', 'OUT'],\n",
              " ['решение', 'OUT'],\n",
              " ['после', 'OUT'],\n",
              " ['того', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['майор', 'OUT'],\n",
              " ['милиции', 'OUT'],\n",
              " ['Денис', 'PER'],\n",
              " ['Евсюков', 'PER'],\n",
              " ['устроил', 'OUT'],\n",
              " ['стрельбу', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['супермаркете', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Остров', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['юге', 'OUT'],\n",
              " ['Москвы', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Вместо', 'OUT'],\n",
              " ['Пронина', 'PER'],\n",
              " ['руководителем', 'OUT'],\n",
              " ['столичного', 'OUT'],\n",
              " ['ГУВД', 'ORG'],\n",
              " ['был', 'OUT'],\n",
              " ['назначен', 'OUT'],\n",
              " ['генерал-майор', 'OUT'],\n",
              " ['милиции', 'OUT'],\n",
              " ['Владимир', 'PER'],\n",
              " ['Колокольцев', 'PER'],\n",
              " ['.', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Олимпстрой', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['созданный', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['2007', 'OUT'],\n",
              " ['году', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['осуществляет', 'OUT'],\n",
              " ['управленческие', 'OUT'],\n",
              " ['функции', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['связанные', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['инженерными', 'OUT'],\n",
              " ['изысканиями', 'OUT'],\n",
              " ['при', 'OUT'],\n",
              " ['строительстве', 'OUT'],\n",
              " ['объектов', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['необходимых', 'OUT'],\n",
              " ['для', 'OUT'],\n",
              " ['проведения', 'OUT'],\n",
              " ['Олимпиады', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Сочи', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Кроме', 'OUT'],\n",
              " ['того', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['занимается', 'OUT'],\n",
              " ['их', 'OUT'],\n",
              " ['проектированием', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['строительством', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['реконструкцией', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['организацией', 'OUT'],\n",
              " ['их', 'OUT'],\n",
              " ['эксплуатации', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Всего', 'OUT'],\n",
              " ['к', 'OUT'],\n",
              " ['Олимпийским', 'OUT'],\n",
              " ['играм-2014', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Сочи', 'LOC'],\n",
              " ['планируется', 'OUT'],\n",
              " ['возвести', 'OUT'],\n",
              " ['несколько', 'OUT'],\n",
              " ['сотен', 'OUT'],\n",
              " ['различных', 'OUT'],\n",
              " ['объектов', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Зимняя', 'OUT'],\n",
              " ['Олимпиада', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Сочи', 'LOC'],\n",
              " ['станет', 'OUT'],\n",
              " ['самой', 'OUT'],\n",
              " ['дорогостоящей', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['истории', 'OUT'],\n",
              " [':', 'OUT'],\n",
              " ['всего', 'OUT'],\n",
              " ['Россия', 'GEOPOLIT'],\n",
              " ['потратит', 'OUT'],\n",
              " ['950', 'OUT'],\n",
              " ['миллиардов', 'OUT'],\n",
              " ['рублей', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['подготовку', 'OUT'],\n",
              " ['к', 'OUT'],\n",
              " ['Сочи-2014', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Суд', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['обязал', 'OUT'],\n",
              " ['вернуть', 'OUT'],\n",
              " ['останки', 'OUT'],\n",
              " ['детей', 'OUT'],\n",
              " ['Манделы', 'PER'],\n",
              " ['на', 'OUT'],\n",
              " ['место', 'OUT'],\n",
              " ['захоронения', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['то', 'OUT'],\n",
              " ['время', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['Нельсон', 'PER'],\n",
              " ['Мандела', 'PER'],\n",
              " ['находится', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['больнице', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['критическом', 'OUT'],\n",
              " ['состоянии', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['разразился', 'OUT'],\n",
              " ['скандал', 'OUT'],\n",
              " ['о', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['последнем', 'OUT'],\n",
              " ['пристанище', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Суд', 'OUT'],\n",
              " ['удовлетворил', 'OUT'],\n",
              " ['иск', 'OUT'],\n",
              " ['старшей', 'OUT'],\n",
              " ['дочери', 'OUT'],\n",
              " ['Манделы', 'PER'],\n",
              " ['к', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['внуку', 'OUT'],\n",
              " ['о', 'OUT'],\n",
              " ['том', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['чтобы', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['был', 'OUT'],\n",
              " ['похоронен', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['деревне', 'OUT'],\n",
              " ['Куну', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Внук', 'OUT'],\n",
              " ['Нельсона', 'PER'],\n",
              " ['Манделы', 'PER'],\n",
              " ['Мандла', 'PER'],\n",
              " ['Мандела', 'PER'],\n",
              " ['Суд', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['обязал', 'OUT'],\n",
              " ['внука', 'OUT'],\n",
              " ['экс-президента', 'OUT'],\n",
              " ['страны', 'OUT'],\n",
              " ['Мандлу', 'PER'],\n",
              " ['Манделу', 'PER'],\n",
              " ['вернуть', 'OUT'],\n",
              " ['останки', 'OUT'],\n",
              " ['троих', 'OUT'],\n",
              " ['детей', 'OUT'],\n",
              " ['Нельсона', 'PER'],\n",
              " ['Манделы', 'PER'],\n",
              " ['в', 'OUT'],\n",
              " ['деревню', 'OUT'],\n",
              " ['Куну', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['где', 'OUT'],\n",
              " ['тот', 'OUT'],\n",
              " ['вырос', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['сообщает', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['субботу', 'OUT'],\n",
              " ['агентство', 'OUT'],\n",
              " ['Рейтер', 'MEDIA'],\n",
              " ['.', 'OUT'],\n",
              " ['Скандал', 'OUT'],\n",
              " ['о', 'OUT'],\n",
              " ['последнем', 'OUT'],\n",
              " ['пристанище', 'OUT'],\n",
              " ['Манделы', 'PER'],\n",
              " ['стал', 'OUT'],\n",
              " ['достоянием', 'OUT'],\n",
              " ['общественности', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['то', 'OUT'],\n",
              " ['время', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['сам', 'OUT'],\n",
              " ['экс-президент', 'OUT'],\n",
              " ['находится', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['критическом', 'OUT'],\n",
              " ['состоянии', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['больнице', 'OUT'],\n",
              " ['Претории', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Чтобы', 'OUT'],\n",
              " ['повысить', 'OUT'],\n",
              " ['престиж', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['туристическую', 'OUT'],\n",
              " ['привлекательность', 'OUT'],\n",
              " ['своей', 'OUT'],\n",
              " ['родной', 'OUT'],\n",
              " ['деревни', 'OUT'],\n",
              " ['Мвезо', 'LOC'],\n",
              " [',', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['внук-депутат', 'OUT'],\n",
              " ['решил', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['2005', 'OUT'],\n",
              " ['году', 'OUT'],\n",
              " ['перезахоронить', 'OUT'],\n",
              " ['там', 'OUT'],\n",
              " ['останки', 'OUT'],\n",
              " ['детей', 'OUT'],\n",
              " ['экс-президента', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['надежде', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['Манделу', 'PER'],\n",
              " ['также', 'OUT'],\n",
              " ['похоронят', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Мвезо', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Помимо', 'OUT'],\n",
              " ['усыпальницы', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['планирует', 'OUT'],\n",
              " ['создать', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['деревне', 'OUT'],\n",
              " ['отель', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['футбольный', 'OUT'],\n",
              " ['стадион', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Однако', 'OUT'],\n",
              " ['старшая', 'OUT'],\n",
              " ['дочь', 'OUT'],\n",
              " ['Манделы', 'PER'],\n",
              " ['Маказиве', 'PER'],\n",
              " ['и', 'OUT'],\n",
              " ['другие', 'OUT'],\n",
              " ['15', 'OUT'],\n",
              " ['родственников', 'OUT'],\n",
              " ['выступили', 'OUT'],\n",
              " ['против', 'OUT'],\n",
              " ['этого', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['настаивая', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['чтобы', 'OUT'],\n",
              " ['первый', 'OUT'],\n",
              " ['темнокожий', 'OUT'],\n",
              " ['президент', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['был', 'OUT'],\n",
              " ['похоронен', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['их', 'OUT'],\n",
              " ['деревне', 'OUT'],\n",
              " ['—', 'OUT'],\n",
              " ['Куну', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['четверг', 'OUT'],\n",
              " ['суд', 'OUT'],\n",
              " ['удовлетворил', 'OUT'],\n",
              " ['иск', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['однако', 'OUT'],\n",
              " ['уведомить', 'OUT'],\n",
              " ['Мандлу', 'PER'],\n",
              " ['о', 'OUT'],\n",
              " ['решении', 'OUT'],\n",
              " ['суда', 'OUT'],\n",
              " ['должным', 'OUT'],\n",
              " ['образом', 'OUT'],\n",
              " ['не', 'OUT'],\n",
              " ['удалось', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['По', 'OUT'],\n",
              " ['информации', 'OUT'],\n",
              " ['Рейтер', 'MEDIA'],\n",
              " [',', 'OUT'],\n",
              " ['шериф', 'OUT'],\n",
              " ['не', 'OUT'],\n",
              " ['смог', 'OUT'],\n",
              " ['попасть', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['дом', 'OUT'],\n",
              " ['внука', 'OUT'],\n",
              " ['Манделы', 'PER'],\n",
              " ['и', 'OUT'],\n",
              " ['приколол', 'OUT'],\n",
              " ['решение', 'OUT'],\n",
              " ['суда', 'OUT'],\n",
              " ['к', 'OUT'],\n",
              " ['стене', 'OUT'],\n",
              " ['или', 'OUT'],\n",
              " ['к', 'OUT'],\n",
              " ['двери', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Представитель', 'OUT'],\n",
              " ['Мандлы', 'PER'],\n",
              " ['заявила', 'OUT'],\n",
              " ['агентству', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['ее', 'OUT'],\n",
              " ['начальник', 'OUT'],\n",
              " ['никаких', 'OUT'],\n",
              " ['бумаг', 'OUT'],\n",
              " ['не', 'OUT'],\n",
              " ['получал', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Как', 'OUT'],\n",
              " ['отмечает', 'OUT'],\n",
              " ['издание', 'OUT'],\n",
              " ['Independent', 'MEDIA'],\n",
              " [',', 'OUT'],\n",
              " ['сам', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['родился', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Мвезо', 'LOC'],\n",
              " [',', 'OUT'],\n",
              " ['но', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['следует', 'OUT'],\n",
              " ['из', 'OUT'],\n",
              " ['оставленного', 'OUT'],\n",
              " ['им', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['1997', 'OUT'],\n",
              " ['году', 'OUT'],\n",
              " ['завещания', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['выразил', 'OUT'],\n",
              " ['желание', 'OUT'],\n",
              " ['быть', 'OUT'],\n",
              " ['похороненным', 'OUT'],\n",
              " ['рядом', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['родными', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Куну', 'LOC'],\n",
              " [',', 'OUT'],\n",
              " ['где', 'OUT'],\n",
              " ['прошло', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['детство', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Рядом', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['могилой', 'OUT'],\n",
              " ['экс-президент', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['завещал', 'OUT'],\n",
              " ['разбить', 'OUT'],\n",
              " ['сад', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['память', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['начале', 'OUT'],\n",
              " ['июня', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['попал', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['госпиталь', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Претории', 'LOC'],\n",
              " ['с', 'OUT'],\n",
              " ['рецидивом', 'OUT'],\n",
              " ['легочной', 'OUT'],\n",
              " ['инфекции', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Несколько', 'OUT'],\n",
              " ['дней', 'OUT'],\n",
              " ['назад', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['состояние', 'OUT'],\n",
              " ['стало', 'OUT'],\n",
              " ['критическим', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['хотя', 'OUT'],\n",
              " ['затем', 'OUT'],\n",
              " ['значительно', 'OUT'],\n",
              " ['улучшилось', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Известный', 'OUT'],\n",
              " ['борец', 'OUT'],\n",
              " ['против', 'OUT'],\n",
              " ['режима', 'OUT'],\n",
              " ['апартеида', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['провел', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['тюрьме', 'OUT'],\n",
              " ['27', 'OUT'],\n",
              " ['лет', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['мае', 'OUT'],\n",
              " ['1994', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['стал', 'OUT'],\n",
              " ['первым', 'OUT'],\n",
              " ['чернокожим', 'OUT'],\n",
              " ['президентом', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['и', 'OUT'],\n",
              " ['руководил', 'OUT'],\n",
              " ['государством', 'OUT'],\n",
              " ['до', 'OUT'],\n",
              " ['июня', 'OUT'],\n",
              " ['1999', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['1993', 'OUT'],\n",
              " ['году', 'OUT'],\n",
              " ['был', 'OUT'],\n",
              " ['награжден', 'OUT'],\n",
              " ['Нобелевской', 'OUT'],\n",
              " ['премией', 'OUT'],\n",
              " ['мира', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Чем', 'OUT'],\n",
              " ['известен', 'OUT'],\n",
              " ['Нельсон', 'PER'],\n",
              " ['Мандела', 'PER'],\n",
              " ['Нельсон', 'PER'],\n",
              " ['Мандела', 'PER'],\n",
              " ['стал', 'OUT'],\n",
              " ['первым', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['истории', 'OUT'],\n",
              " ['чернокожим', 'OUT'],\n",
              " ['президентом', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['.', 'OUT'],\n",
              " ['Он', 'OUT'],\n",
              " ['руководил', 'OUT'],\n",
              " ['государством', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['мая', 'OUT'],\n",
              " ['1994', 'OUT'],\n",
              " ['по', 'OUT'],\n",
              " ['июнь', 'OUT'],\n",
              " ['1999', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['За', 'OUT'],\n",
              " ['свою', 'OUT'],\n",
              " ['активную', 'OUT'],\n",
              " ['деятельность', 'OUT'],\n",
              " ['против', 'OUT'],\n",
              " ['режима', 'OUT'],\n",
              " ['апартеида', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['провел', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['тюрьме', 'OUT'],\n",
              " ['27', 'OUT'],\n",
              " ['лет', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['1993', 'OUT'],\n",
              " ['году', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['был', 'OUT'],\n",
              " ['награжден', 'OUT'],\n",
              " ['Нобелевской', 'OUT'],\n",
              " ['премией', 'OUT'],\n",
              " ['мира', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Как', 'OUT'],\n",
              " ['у', 'OUT'],\n",
              " ['экс-президента', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['обострились', 'OUT'],\n",
              " ['проблемы', 'OUT'],\n",
              " ['со', 'OUT'],\n",
              " ['здоровьем', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['начале', 'OUT'],\n",
              " ['декабря', 'OUT'],\n",
              " ['2012', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['Мандела', 'PER'],\n",
              " ['был', 'OUT'],\n",
              " ['госпитализирован', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Йоханнесбурге', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['Врачи', 'OUT'],\n",
              " ['провели', 'OUT'],\n",
              " ['ряд', 'OUT'],\n",
              " ['тестов', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['которые', 'OUT'],\n",
              " ['выявили', 'OUT'],\n",
              " ['рецидив', 'OUT'],\n",
              " ['легочной', 'OUT'],\n",
              " ['инфекции', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['потребовавший', 'OUT'],\n",
              " ['соответствующего', 'OUT'],\n",
              " ['лечения', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Позже', 'OUT'],\n",
              " ['экс-президенту', 'OUT'],\n",
              " ['ЮАР', 'GEOPOLIT'],\n",
              " ['была', 'OUT'],\n",
              " ['успешно', 'OUT'],\n",
              " ['проведена', 'OUT'],\n",
              " ['операция', 'OUT'],\n",
              " ['по', 'OUT'],\n",
              " ['удалению', 'OUT'],\n",
              " ['камней', 'OUT'],\n",
              " ['из', 'OUT'],\n",
              " ['желчного', 'OUT'],\n",
              " ['пузыря', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Незадолго', 'OUT'],\n",
              " ['до', 'OUT'],\n",
              " ['наступления', 'OUT'],\n",
              " ['нового', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['он', 'OUT'],\n",
              " ['был', 'OUT'],\n",
              " ['выписан', 'OUT'],\n",
              " ['из', 'OUT'],\n",
              " ['больницы', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Йеменская', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Аль-Каеда', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " ['завладела', 'OUT'],\n",
              " ['обломками', 'OUT'],\n",
              " ['американского', 'OUT'],\n",
              " ['беспилотника', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['Йемене', 'GEOPOLIT'],\n",
              " ['разбился', 'OUT'],\n",
              " ['беспилотный', 'OUT'],\n",
              " ['летательный', 'OUT'],\n",
              " ['аппарат', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['предположительно', 'OUT'],\n",
              " ['принадлежавший', 'OUT'],\n",
              " ['США', 'GEOPOLIT'],\n",
              " ['.', 'OUT'],\n",
              " ['Об', 'OUT'],\n",
              " ['этом', 'OUT'],\n",
              " ['агентству', 'OUT'],\n",
              " ['Agence', 'MEDIA'],\n",
              " ['France-Presse', 'MEDIA'],\n",
              " ['сообщили', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['местной', 'OUT'],\n",
              " ['полиции', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Беспилотник', 'OUT'],\n",
              " ['упал', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['окрестностях', 'OUT'],\n",
              " ['города', 'OUT'],\n",
              " ['Лодер', 'LOC'],\n",
              " [',', 'OUT'],\n",
              " ['который', 'OUT'],\n",
              " ['входит', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['южную', 'OUT'],\n",
              " ['мухафазу', 'OUT'],\n",
              " ['Абьян', 'LOC'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['этом', 'OUT'],\n",
              " ['регионе', 'OUT'],\n",
              " ['Йемена', 'GEOPOLIT'],\n",
              " ['особенно', 'OUT'],\n",
              " ['сильны', 'OUT'],\n",
              " ['позиции', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Аль-Каеды', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['отмечает', 'OUT'],\n",
              " ['агентство', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Как', 'OUT'],\n",
              " ['сообщают', 'OUT'],\n",
              " ['местные', 'OUT'],\n",
              " ['жители', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['боевики', 'OUT'],\n",
              " ['террористической', 'OUT'],\n",
              " ['сети', 'OUT'],\n",
              " ['первыми', 'OUT'],\n",
              " ['прибыли', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['место', 'OUT'],\n",
              " ['крушения', 'OUT'],\n",
              " ['беспилотника', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['завладели', 'OUT'],\n",
              " ['его', 'OUT'],\n",
              " ['обломками', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['По', 'OUT'],\n",
              " ['предварительной', 'OUT'],\n",
              " ['информации', 'OUT'],\n",
              " ['йеменской', 'OUT'],\n",
              " ['полиции', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['окрестностях', 'OUT'],\n",
              " ['Лодера', 'LOC'],\n",
              " ['упал', 'OUT'],\n",
              " ['БПЛА', 'OUT'],\n",
              " ['типа', 'OUT'],\n",
              " ['Predator', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['которые', 'OUT'],\n",
              " ['широко', 'OUT'],\n",
              " ['используются', 'OUT'],\n",
              " ['ЦРУ', 'ORG'],\n",
              " ['в', 'OUT'],\n",
              " ['борьбе', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['боевиками', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['территории', 'OUT'],\n",
              " ['Пакистана', 'GEOPOLIT'],\n",
              " ['и', 'OUT'],\n",
              " ['Афганистана', 'GEOPOLIT'],\n",
              " ['.', 'OUT'],\n",
              " ['Беспилотник', 'OUT'],\n",
              " ['может', 'OUT'],\n",
              " ['использоваться', 'OUT'],\n",
              " ['для', 'OUT'],\n",
              " ['уничтожения', 'OUT'],\n",
              " ['наземных', 'OUT'],\n",
              " ['целей', 'OUT'],\n",
              " ['или', 'OUT'],\n",
              " ['же', 'OUT'],\n",
              " ['выполнять', 'OUT'],\n",
              " ['исключительно', 'OUT'],\n",
              " ['разведывательные', 'OUT'],\n",
              " ['функции', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Следует', 'OUT'],\n",
              " ['отметить', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['августе', 'OUT'],\n",
              " ['2010', 'OUT'],\n",
              " ['года', 'OUT'],\n",
              " ['американская', 'OUT'],\n",
              " ['газета', 'OUT'],\n",
              " ['The', 'MEDIA'],\n",
              " ['Washington', 'MEDIA'],\n",
              " ['Post', 'MEDIA'],\n",
              " ['написала', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['именно', 'OUT'],\n",
              " ['йеменская', 'OUT'],\n",
              " ['ячейка', 'OUT'],\n",
              " ['\"', 'OUT'],\n",
              " ['Аль-Каеды', 'ORG'],\n",
              " ['\"', 'OUT'],\n",
              " ['сейчас', 'OUT'],\n",
              " ['представляет', 'OUT'],\n",
              " ['наибольшую', 'OUT'],\n",
              " ['угрозу', 'OUT'],\n",
              " ['для', 'OUT'],\n",
              " ['безопасности', 'OUT'],\n",
              " ['западных', 'OUT'],\n",
              " ['стран', 'OUT'],\n",
              " ['и', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['частности', 'OUT'],\n",
              " ['США', 'GEOPOLIT'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['связи', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['этим', 'OUT'],\n",
              " ['ЦРУ', 'ORG'],\n",
              " [',', 'OUT'],\n",
              " ['как', 'OUT'],\n",
              " ['сообщалось', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['активизировало', 'OUT'],\n",
              " ['свою', 'OUT'],\n",
              " ['деятельность', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['территории', 'OUT'],\n",
              " ['Йемена', 'GEOPOLIT'],\n",
              " [',', 'OUT'],\n",
              " ['например', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['начав', 'OUT'],\n",
              " ['использовать', 'OUT'],\n",
              " ['там', 'OUT'],\n",
              " ['беспилотники', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Глава', 'OUT'],\n",
              " ['московского', 'OUT'],\n",
              " ['СКП', 'ORG'],\n",
              " ['А', 'PER'],\n",
              " ['.', 'PER'],\n",
              " ['Багмет', 'PER'],\n",
              " ['окончательно', 'OUT'],\n",
              " ['лишился', 'OUT'],\n",
              " ['поста', 'OUT'],\n",
              " ['Сегодня', 'OUT'],\n",
              " ['стало', 'OUT'],\n",
              " ['известно', 'OUT'],\n",
              " ['о', 'OUT'],\n",
              " ['смене', 'OUT'],\n",
              " ['руководства', 'OUT'],\n",
              " ['московского', 'OUT'],\n",
              " ['управления', 'OUT'],\n",
              " ['Следственного', 'ORG'],\n",
              " ['комитета', 'ORG'],\n",
              " ['при', 'OUT'],\n",
              " ['прокуратуре', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ['Как', 'OUT'],\n",
              " ['сообщили', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['СКП', 'ORG'],\n",
              " [',', 'OUT'],\n",
              " ['приказом', 'OUT'],\n",
              " ['председателя', 'OUT'],\n",
              " ['Следственного', 'ORG'],\n",
              " ['комитета', 'ORG'],\n",
              " ['Александра', 'PER'],\n",
              " ['Бастрыкина', 'PER'],\n",
              " ['Анатолий', 'PER'],\n",
              " ['Багмет', 'PER'],\n",
              " ['снят', 'OUT'],\n",
              " ['с', 'OUT'],\n",
              " ['должности', 'OUT'],\n",
              " ['руководителя', 'OUT'],\n",
              " ['следственного', 'OUT'],\n",
              " ['управления', 'OUT'],\n",
              " ['по', 'OUT'],\n",
              " ['городу', 'OUT'],\n",
              " ['Москве', 'LOC'],\n",
              " ['и', 'OUT'],\n",
              " ['назначен', 'OUT'],\n",
              " ['на', 'OUT'],\n",
              " ['должность', 'OUT'],\n",
              " ['заместителя', 'OUT'],\n",
              " ['руководителя', 'OUT'],\n",
              " ['Главного', 'ORG'],\n",
              " ['управления', 'ORG'],\n",
              " ['криминалистики', 'ORG'],\n",
              " ['Следственного', 'ORG'],\n",
              " ['комитета', 'ORG'],\n",
              " ['.', 'OUT'],\n",
              " ['Новым', 'OUT'],\n",
              " ['начальником', 'OUT'],\n",
              " ['московских', 'OUT'],\n",
              " ['следователей', 'OUT'],\n",
              " ['назначен', 'OUT'],\n",
              " ['главный', 'OUT'],\n",
              " ['федеральный', 'OUT'],\n",
              " ['инспектор', 'OUT'],\n",
              " ['по', 'OUT'],\n",
              " ['Краснодарскому', 'LOC'],\n",
              " ['краю', 'LOC'],\n",
              " ['аппарата', 'OUT'],\n",
              " ['полномочного', 'OUT'],\n",
              " ['представителя', 'OUT'],\n",
              " ['президента', 'OUT'],\n",
              " ['в', 'OUT'],\n",
              " ['Южном', 'LOC'],\n",
              " ['федеральном', 'LOC'],\n",
              " ['округе', 'LOC'],\n",
              " ['Вадим', 'PER'],\n",
              " ['Яковенко', 'PER'],\n",
              " ['.', 'OUT'],\n",
              " ['В', 'OUT'],\n",
              " ['ведомстве', 'OUT'],\n",
              " ['отмечают', 'OUT'],\n",
              " [',', 'OUT'],\n",
              " ['что', 'OUT'],\n",
              " ['В', 'PER'],\n",
              " ['.', 'PER'],\n",
              " ['Яковенко', 'PER'],\n",
              " ['с', 'OUT'],\n",
              " ['1994', 'OUT'],\n",
              " ['г', 'OUT'],\n",
              " ['.', 'OUT'],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])\n",
        "df_words['tag'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9KOKetyUdVj",
        "outputId": "c983f5bd-4317-4614-d929-d93595e4a3d7"
      },
      "id": "A9KOKetyUdVj",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OUT         219214\n",
              "PER          21200\n",
              "ORG          13651\n",
              "LOC           4568\n",
              "GEOPOLIT      4356\n",
              "MEDIA         2482\n",
              "Name: tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "EP4PITBuUgfN",
        "outputId": "b3fac9cb-7b56-47fb-b027-d63d5c9f515c"
      },
      "id": "EP4PITBuUgfN",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     word  tag\n",
              "0  Бывший  OUT\n",
              "1   глава  OUT\n",
              "2    ГУВД  ORG"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb4b4208-51e8-4e73-837a-a4fd4e6c7d6b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Бывший</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>глава</td>\n",
              "      <td>OUT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ГУВД</td>\n",
              "      <td>ORG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb4b4208-51e8-4e73-837a-a4fd4e6c7d6b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb4b4208-51e8-4e73-837a-a4fd4e6c7d6b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb4b4208-51e8-4e73-837a-a4fd4e6c7d6b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuSovwAaUqSC",
        "outputId": "8fe89d42-1bc6-410d-9d09-7e16d66f67e7"
      },
      "id": "vuSovwAaUqSC",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(265471, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeBSorD6X0GW",
        "outputId": "4b14dd83-ba64-4512-ae25-934696984eef"
      },
      "id": "WeBSorD6X0GW",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.18.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.22.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.3.7)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "cqRmCfpmUw04"
      },
      "id": "cqRmCfpmUw04",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "metadata": {
        "id": "BqY_UyqIUzEc"
      },
      "id": "BqY_UyqIUzEc",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.apply(len).max(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUWdBlJEVOjY",
        "outputId": "982d1038-37eb-4bc5-eb49-6ea9d0a43058"
      },
      "id": "YUWdBlJEVOjY",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "\n",
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ],
      "metadata": {
        "id": "1qyGiJ1XVSa0"
      },
      "id": "1qyGiJ1XVSa0",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    AUTOTUNE = tf.data.AUTOTUNE     \n",
        "except:\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE \n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "QnDuFvpGVVp1"
      },
      "id": "QnDuFvpGVVp1",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    #ngrams=(1, 3),\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "X6W1M8B4VXYc"
      },
      "id": "X6W1M8B4VXYc",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorize_layer.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT5Y8Y11VZ7g",
        "outputId": "3b035bbf-cdc8-470e-b7f8-83f3f44f8ae5"
      },
      "id": "AT5Y8Y11VZ7g",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29841"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "class modelNER(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(modelNER, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim)\n",
        "        self.gPool = GlobalMaxPooling1D()\n",
        "        self.do1 = Dropout(0.2)\n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.fc2 = Dense(50, activation='relu')\n",
        "        self.fc3 = Dense(6, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        pool_x = self.gPool(x)\n",
        "        \n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.do1(fc_x)\n",
        "        fc_x = self.fc2(fc_x)\n",
        "        fc_x = self.do1(fc_x)\n",
        "        \n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
        "        prob = self.fc3(concat_x)\n",
        "        return prob"
      ],
      "metadata": {
        "id": "dQZ22DdeVcDQ"
      },
      "id": "dQZ22DdeVcDQ",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "lxrRd_g4VfgM"
      },
      "id": "lxrRd_g4VfgM",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d3xChcxUVhXw"
      },
      "id": "d3xChcxUVhXw",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqxV3OfbVjNs",
        "outputId": "73ccd4b0-b313-4fc1-b294-8652d0cdb631"
      },
      "id": "oqxV3OfbVjNs",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12444/12444 [==============================] - 252s 20ms/step - loss: 0.2935 - accuracy: 0.9148 - val_loss: 0.2089 - val_accuracy: 0.9364\n",
            "Epoch 2/3\n",
            "12444/12444 [==============================] - 250s 20ms/step - loss: 0.1243 - accuracy: 0.9630 - val_loss: 0.2193 - val_accuracy: 0.9399\n",
            "Epoch 3/3\n",
            "12444/12444 [==============================] - 247s 20ms/step - loss: 0.1086 - accuracy: 0.9660 - val_loss: 0.2714 - val_accuracy: 0.8851\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f278a35e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = mmodel.predict(valid_x)\n"
      ],
      "metadata": {
        "id": "0k1sgdWdVlBh"
      },
      "id": "0k1sgdWdVlBh",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.argmax(pred, axis=1)"
      ],
      "metadata": {
        "id": "nheRvy4xd_RI"
      },
      "id": "nheRvy4xd_RI",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ],
      "metadata": {
        "id": "yWcAIOGTdzqI"
      },
      "id": "yWcAIOGTdzqI",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy: ', accuracy_score(valid_y, pred))\n",
        "print('recall: ', recall_score(valid_y, pred, average='macro'))\n",
        "print('precision: ', precision_score(valid_y, pred, average='macro'))\n",
        "print('f1: ', f1_score(valid_y, pred, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3HAS_NOd8uI",
        "outputId": "edb71f82-aa55-4d5f-c854-222cbdeed7e5"
      },
      "id": "f3HAS_NOd8uI",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8851404291224687\n",
            "recall:  0.7889055305911139\n",
            "precision:  0.8254121212988142\n",
            "f1:  0.7897164575556807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oyRqaOeKeYbb"
      },
      "id": "oyRqaOeKeYbb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}